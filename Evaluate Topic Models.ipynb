{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic Model in Python: Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "In the previous article, I introduced the concept of topic modeling and walked through the code for developing your first topic model using Latent Dirichlet Allocation (LDA) method in the python using sklearn implementation.\n",
    "\n",
    "Pursuing on that understanding, in this article, I'll go a few steps deeper by outlining the framework to quantitatively evaluate topic models through the measure of topic coherence and share the code template in python using Gensim implementation to allow for end-to-end model development.\n",
    "\n",
    "### Why evaluate topic models?\n",
    "\n",
    "![img](https://tinyurl.com/y3xznjwq)\n",
    "\n",
    "We know probabilistic topic models, such as LDA, are popular tools for analysis of the text, providing both a predictive and latent topic representation of the corpus. There is a longstanding assumption that the latent space discovered by these models is meaningful and useful, and evaluating such assumptions is challenging due to its unsupervised training process. There is a no-gold standard list of topics to compare against every corpus.\n",
    "\n",
    "However, it is equally important to identify if a trained model is objectively good or bad, as well have an ability to compare different models/methods and to do so, we require an objective measure for the quality. Traditionally, and still for many practical applications, to evaluate if \"the correct thing\" has been learned about the corpus, we use implicit knowledge and \"eyeballing\" approaches. Ideally, we'd like to capture this information in a single metric that can be maximized, and compared. Let's take a look at roughly what approaches are commonly used for the evaluation:\n",
    "\n",
    "**Eye Balling Models**\n",
    "- Top N words\n",
    "- Topics / Documents\n",
    "\n",
    "**Intrinsic Evaluation Metrics**\n",
    "- Capturing model semantics\n",
    "- Topics interpretability\n",
    "\n",
    "**Human Judgements**\n",
    "- What is a topic\n",
    "\n",
    "**Extrinsic Evaluation Metrics/Evaluation at task**\n",
    "- Is model good at performing predefined tasks, such as classification\n",
    "\n",
    "Natural language is messy, ambiguous and full of subjective interpretation, and sometimes trying to cleanse ambiguity reduces the language to an unnatural form. Nevertheless, in this article, we'll explore more about topic coherence, and how we can use it to quantitatively justify the model selection.\n",
    "\n",
    "### What is Topic Coherence?\n",
    "\n",
    "Perplexity is often used as an example of an intrinsic evaluation measure. It comes from the language modeling community and aims to capture how surprised a model is of new data it has not seen before. It is measured as the normalized log-likelihood of a held-out test set.\n",
    "\n",
    "Focussing on the log-likelihood part, you can think of the perplexity metric as measuring how probable some new unseen data is given the model that was learned earlier. That is to say, how well does the model represent or reproduce the statistics of the held-out data.\n",
    "\n",
    "However, past research has shown that predictive likelihood (or equivalently, perplexity) and human judgment are often not correlated, and even sometimes slightly anti-correlated. And that served as a motivation for more work trying to model the human judgment, and thus `Topic Coherence`.\n",
    "\n",
    "The topic coherence concept combines a number of papers into one framework that allows evaluating the coherence of topics inferred by a topic model. But,\n",
    "\n",
    "#### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. But,\n",
    "\n",
    "#### What is coherence?\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is \"the game is a team sport\", \"the game is played with a ball\", \"the game demands great physical efforts\"\n",
    "\n",
    "### Coherence Measures\n",
    "\n",
    "1. `C_v` measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
    "2. `C_p` is based on a sliding window, one-preceding segmentation of the top words and the confirmation measure of Fitelson's coherence\n",
    "3. `C_uci` measure is based on a sliding window and the pointwise mutual information (PMI) of all word pairs of the given top words\n",
    "4. `C_umass` is based on document cooccurrence counts, a one-preceding segmentation and a logarithmic conditional probability as confirmation measure\n",
    "5. `C_npmi` is an enhanced version of the C_uci coherence using the normalized pointwise mutual information (NPMI)\n",
    "6. `C_a` is baseed on a context window, a pairwise comparison of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install dependent packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyLDAvis\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 759kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/lib/python2.7/dist-packages (from PyLDAvis)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python2.7/site-packages (from PyLDAvis)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python2.7/site-packages (from PyLDAvis)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python2.7/dist-packages (from PyLDAvis)\n",
      "Collecting joblib>=0.8.4 (from PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/42/155696f85f344c066e17af287359c9786b436b1bf86029bb3411283274f3/joblib-0.14.0-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 4.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python2.7/dist-packages (from PyLDAvis)\n",
      "Collecting numexpr (from PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/e9/b72415d496b711baaf040098342b15ecbcceb0808325fc672f9c0177887b/numexpr-2.7.0-cp27-cp27mu-manylinux1_x86_64.whl (162kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 5.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytest (from PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/f1/187a98b8f913a8f3a53d213cca2fae19718565f36165804d7f4f91fe5b76/pytest-4.6.6-py2.py3-none-any.whl (230kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 4.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from PyLDAvis)\n",
      "Collecting funcy (from PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/3a/fc8323f913e8a9c6f33f7203547f8a2171223da5ed965f2541dafb10aa09/funcy-1.13-py2.py3-none-any.whl\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python2.7/dist-packages (from numpy>=1.9.2->PyLDAvis)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python2.7/dist-packages (from numpy>=1.9.2->PyLDAvis)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python2.7/dist-packages (from numpy>=1.9.2->PyLDAvis)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python2.7/dist-packages (from numpy>=1.9.2->PyLDAvis)\n",
      "Requirement already satisfied: icc-rt in /usr/local/lib/python2.7/dist-packages (from numpy>=1.9.2->PyLDAvis)\n",
      "Requirement already satisfied: intel-numpy in /usr/local/lib/python2.7/dist-packages (from scipy>=0.18.0->PyLDAvis)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas>=0.17.0->PyLDAvis)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas>=0.17.0->PyLDAvis)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from jinja2>=2.7.2->PyLDAvis)\n",
      "Collecting importlib-metadata>=0.12; python_version < \"3.8\" (from pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/d2/40b3fa882147719744e6aa50ac39cf7a22a913cbcba86a0371176c425a3b/importlib_metadata-0.23-py2.py3-none-any.whl\n",
      "Requirement already satisfied: funcsigs>=1.0; python_version < \"3.0\" in /usr/local/lib/python2.7/dist-packages (from pytest->PyLDAvis)\n",
      "Collecting pluggy<1.0,>=0.12 (from pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python2.7/dist-packages (from pytest->PyLDAvis)\n",
      "Requirement already satisfied: pathlib2>=2.2.0; python_version < \"3.6\" in /usr/local/lib/python2.7/dist-packages (from pytest->PyLDAvis)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from pytest->PyLDAvis)\n",
      "Collecting py>=1.5.0 (from pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/bc/394ad449851729244a97857ee14d7cba61ddb268dce3db538ba2f2ba1f0f/py-1.8.0-py2.py3-none-any.whl (83kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 11.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting more-itertools<6.0.0,>=4.0.0; python_version <= \"2.7\" (from pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/9d/dcfe59e213093695f108508af1214cf9cd95cc5489e46877ec5cb56369e5/more_itertools-5.0.0-py2-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 12.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python2.7/dist-packages (from pytest->PyLDAvis)\n",
      "Collecting packaging (from pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/94/9672c2d4b126e74c4496c6b3c58a8b51d6419267be9e70660ba23374c875/packaging-19.2-py2.py3-none-any.whl\n",
      "Collecting atomicwrites>=1.0 (from pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/90/6155aa926f43f2b2a22b01be7241be3bfd1ceaf7d0b3267213e8127d41f4/atomicwrites-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python2.7/dist-packages (from mkl->numpy>=1.9.2->PyLDAvis)\n",
      "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python2.7/dist-packages (from tbb4py->numpy>=1.9.2->PyLDAvis)\n",
      "Requirement already satisfied: configparser>=3.5; python_version < \"3\" in /usr/local/lib/python2.7/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->PyLDAvis)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/3d/1ee25a26411ba0401b43c6376d2316a71addcc72ef8690b101b4ea56d76a/zipp-0.6.0-py2.py3-none-any.whl\n",
      "Collecting contextlib2; python_version < \"3\" (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->PyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/60/370352f7ef6aa96c52fb001831622f50f923c1d575427d021b8ab3311236/contextlib2-0.6.0.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scandir; python_version < \"3.5\" in /usr/local/lib/python2.7/dist-packages (from pathlib2>=2.2.0; python_version < \"3.6\"->pytest->PyLDAvis)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python2.7/dist-packages (from packaging->pytest->PyLDAvis)\n",
      "Building wheels for collected packages: PyLDAvis\n",
      "  Running setup.py bdist_wheel for PyLDAvis ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
      "Successfully built PyLDAvis\n",
      "Installing collected packages: joblib, numexpr, more-itertools, zipp, contextlib2, importlib-metadata, pluggy, py, packaging, atomicwrites, pytest, funcy, PyLDAvis\n",
      "Successfully installed PyLDAvis-2.1.2 atomicwrites-1.3.0 contextlib2-0.6.0.post1 funcy-1.13 importlib-metadata-0.23 joblib-0.14.0 more-itertools-5.0.0 numexpr-2.7.0 packaging-19.2 pluggy-0.13.0 py-1.8.0 pytest-4.6.6 zipp-0.6.0\n",
      "Collecting spacy\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/fa/195de6a7544550c79ec0d7dd62c62562f20023b3d8ce5eed6917c5719851/spacy-2.2.1-cp27-cp27mu-manylinux1_x86_64.whl (10.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.2MB 121kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<7.2.0,>=7.1.1 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/e1/bb0969cacdc65398a78480f8f8511be037490c5807c22e46758e2bc54e3a/thinc-7.1.1-cp27-cp27mu-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.1MB 632kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/27/32d860083e0708e36a2266bed865dba4b55c991a84688932122e48ef65b4/preshed-3.0.2-cp27-cp27mu-manylinux1_x86_64.whl (113kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 10.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pathlib==1.0.1; python_version < \"3.4\" (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 9.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/31/247b34db5ab06afaf5512481e77860fb4cd7a0c0ddff9d2566651c8c2f07/murmurhash-1.0.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting plac<1.0.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/df/b1/4ff2cbd423184bd68e85f1daa6692753cd7710b0ba68552eb64542906a57/cymem-2.0.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python2.7/dist-packages (from spacy)\n",
      "Collecting blis<0.5.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/db/bfae863870f79260e57e293dd835e848e8450d2a2c9e273795b13060ff86/blis-0.4.1-cp27-cp27mu-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.7MB 353kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<1.1.0,>=0.1.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/96/4c65e8f2aec3a9c9f40f0d0debdd3035f1cbf81947633a1a2cb59532b305/srsly-0.1.0-cp27-cp27mu-manylinux1_x86_64.whl (176kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.2.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/be/ba/08c53c55cc97f62310ed83e1a4d91e424f221645c88c2dddd41f179fd1f7/wasabi-0.2.2.tar.gz\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python2.7/dist-packages (from thinc<7.2.0,>=7.1.1->spacy)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy)\n",
      "Requirement already satisfied: icc-rt in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: intel-numpy in /usr/local/lib/python2.7/dist-packages (from mkl-random->numpy>=1.15.0->spacy)\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python2.7/dist-packages (from mkl->numpy>=1.15.0->spacy)\n",
      "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python2.7/dist-packages (from tbb4py->numpy>=1.15.0->spacy)\n",
      "Building wheels for collected packages: pathlib, wasabi\n",
      "  Running setup.py bdist_wheel for pathlib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/f9/b2/4a/68efdfe5093638a9918bd1bb734af625526e849487200aa171\n",
      "  Running setup.py bdist_wheel for wasabi ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/b3/2c/d1/78fd1255da73ff77b372ecc56bcdb15115ab0882bb6f67af17\n",
      "Successfully built pathlib wasabi\n",
      "Installing collected packages: murmurhash, cymem, preshed, pathlib, srsly, plac, blis, wasabi, thinc, spacy\n",
      "Successfully installed blis-0.4.1 cymem-2.0.2 murmurhash-1.0.2 pathlib-1.0.1 plac-0.9.6 preshed-3.0.2 spacy-2.2.1 srsly-0.1.0 thinc-7.1.1 wasabi-0.2.2\n",
      "Collecting en_core_web_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm==2.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz (12.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.0MB 129.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /home/jupyter/.local/lib/python2.7/site-packages (from en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: pathlib==1.0.1; python_version < \"3.4\" in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python2.7/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/jupyter/.local/lib/python2.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python2.7/dist-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: icc-rt in /usr/local/lib/python2.7/dist-packages (from numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: intel-numpy in /usr/local/lib/python2.7/dist-packages (from mkl-random->numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python2.7/dist-packages (from mkl->numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python2.7/dist-packages (from tbb4py->numpy>=1.15.0->spacy>=2.2.0->en_core_web_sm==2.2.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# To be run only once\n",
    "if 0 == 1:\n",
    "    !pip install gensim\n",
    "    !pip install PyLDAvis\n",
    "    !pip install spacy\n",
    "    !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation\n",
    "\n",
    "#### Loading data\n",
    "\n",
    "For this tutorial, we’ll use the dataset of papers published in NIPS conference. The NIPS conference (Neural Information Processing Systems) is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_158/img/nips_logo.png\" alt=\"The logo of NIPS (Neural Information Processing Systems)\">\n",
    "\n",
    "Let’s start by looking at the content of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "# Read data into papers\n",
    "papers = pd.read_csv('./data/NIPS Papers/papers.csv')\n",
    "\n",
    "# Print head\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n",
    "Since the goal of this analysis is to perform topic modeling, we will solely focus on the text data from each paper, and drop other metadata columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>Truncated Variance Reduction: A Unified Approa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>Stress, noradrenaline, and realistic predictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>On a Theory of Nonparametric Pairwise Similari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>An Analog Neural Network Inspired by\\nFractal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5784</th>\n",
       "      <td>Hierarchical Deep Reinforcement Learning:\\nInt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_text\n",
       "5614  Truncated Variance Reduction: A Unified Approa...\n",
       "2870  Stress, noradrenaline, and realistic predictio...\n",
       "4754  On a Theory of Nonparametric Pairwise Similari...\n",
       "6515  An Analog Neural Network Inspired by\\nFractal ...\n",
       "5784  Hierarchical Deep Reinforcement Learning:\\nInt..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the columns\n",
    "papers = papers.drop(columns=['id', 'title', 'abstract', \n",
    "                              'event_type', 'pdf_name', 'year'], axis=1)\n",
    "\n",
    "# sample only 100 papers\n",
    "papers = papers.sample(100)\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove punctuation/lower casing\n",
    "\n",
    "Next, let’s perform a simple preprocessing on the content of paper_text column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5614    truncated variance reduction: a unified approa...\n",
       "2870    stress noradrenaline and realistic prediction ...\n",
       "4754    on a theory of nonparametric pairwise similari...\n",
       "6515    an analog neural network inspired by\\nfractal ...\n",
       "5784    hierarchical deep reinforcement learning:\\nint...\n",
       "Name: paper_text_processed, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers['paper_text_processed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize words and further clean-up text\n",
    "\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'truncated', u'variance', u'reduction', u'unified', u'approach', u'to', u'bayesian', u'optimization', u'and', u'level', u'set', u'estimation', u'ilija', u'bogunovic', u'jonathan', u'scarlett', u'andreas', u'krause', u'volkan', u'cevher', u'laboratory', u'for', u'information', u'and', u'inference', u'systems', u'lions', u'epfl', u'learning', u'and']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Bigram and Trigram Models\n",
    "\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring. Some examples in our example are: 'back_bumper', 'oil_leakage', 'maryland_college_park' etc.\n",
    "\n",
    "Gensim's Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords, Make Bigrams and Lemmatize\n",
    "\n",
    "The phrase models are ready. Let’s define the functions to remove the stopwords, make trigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the functions in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'truncate', u'variance_reduction', u'unify', u'approach', u'bayesian', u'optimization', u'level', u'set', u'estimation', u'system', u'lion', u'epfl', u'learn', u'system', u'present', u'new', u'truncate', u'treat', u'bayesian', u'optimization', u'level', u'set', u'estimation', u'lse', u'gaussian_processe', u'unify', u'fashion', u'greedily', u'shrink', u'sum']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation: Corpus and Dictionary\n",
    "\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 10), (3, 7), (4, 1), (5, 3), (6, 1), (7, 3), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 4), (15, 1), (16, 1), (17, 2), (18, 1), (19, 13), (20, 3), (21, 1), (22, 1), (23, 1), (24, 7), (25, 3), (26, 1), (27, 3), (28, 4), (29, 3)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the base topic model\n",
    "\n",
    "We have everything required to train the base LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we'll use default for the base model).\n",
    "\n",
    "chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
    "\n",
    "passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be \"epochs\". iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of \"passes\" and \"iterations\" high enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the topics in LDA model\n",
    "The above LDA model is built with 10 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
    "\n",
    "You can see the keywords for each topic and the weightage(importance) of each keyword using `lda_model.print_topics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  u'0.010*\"target\" + 0.010*\"neuron\" + 0.009*\"network\" + 0.008*\"time\" + 0.007*\"model\" + 0.007*\"protein\" + 0.007*\"search\" + 0.007*\"image\" + 0.007*\"current\" + 0.006*\"error\"'),\n",
      " (1,\n",
      "  u'0.016*\"model\" + 0.011*\"use\" + 0.009*\"network\" + 0.007*\"time\" + 0.007*\"learn\" + 0.007*\"training\" + 0.006*\"datum\" + 0.006*\"set\" + 0.006*\"function\" + 0.005*\"system\"'),\n",
      " (2,\n",
      "  u'0.013*\"network\" + 0.010*\"object\" + 0.008*\"point\" + 0.008*\"problem\" + 0.008*\"use\" + 0.008*\"value\" + 0.007*\"formulation\" + 0.007*\"base\" + 0.007*\"view\" + 0.007*\"figure\"'),\n",
      " (3,\n",
      "  u'0.015*\"model\" + 0.012*\"datum\" + 0.011*\"set\" + 0.010*\"use\" + 0.008*\"image\" + 0.008*\"learn\" + 0.006*\"matrix\" + 0.006*\"problem\" + 0.006*\"feature\" + 0.006*\"give\"'),\n",
      " (4,\n",
      "  u'0.022*\"network\" + 0.013*\"training\" + 0.012*\"set\" + 0.010*\"color\" + 0.010*\"performance\" + 0.009*\"datum\" + 0.009*\"committee\" + 0.009*\"arm\" + 0.008*\"use\" + 0.008*\"sample\"'),\n",
      " (5,\n",
      "  u'0.012*\"model\" + 0.008*\"visual\" + 0.007*\"network\" + 0.007*\"function\" + 0.006*\"problem\" + 0.006*\"datum\" + 0.005*\"figure\" + 0.005*\"input\" + 0.005*\"use\" + 0.005*\"constraint\"'),\n",
      " (6,\n",
      "  u'0.011*\"set\" + 0.010*\"problem\" + 0.010*\"error\" + 0.010*\"task\" + 0.010*\"learn\" + 0.008*\"network\" + 0.007*\"function\" + 0.007*\"term\" + 0.007*\"method\" + 0.007*\"use\"'),\n",
      " (7,\n",
      "  u'0.011*\"set\" + 0.011*\"use\" + 0.010*\"sample\" + 0.009*\"datum\" + 0.008*\"method\" + 0.008*\"feature\" + 0.008*\"distribution\" + 0.008*\"function\" + 0.008*\"model\" + 0.008*\"point\"'),\n",
      " (8,\n",
      "  u'0.008*\"state\" + 0.008*\"use\" + 0.008*\"network\" + 0.007*\"weight\" + 0.007*\"system\" + 0.006*\"spike\" + 0.006*\"model\" + 0.006*\"value\" + 0.005*\"compute\" + 0.005*\"result\"'),\n",
      " (9,\n",
      "  u'0.026*\"state\" + 0.017*\"fingerprint\" + 0.011*\"agent\" + 0.011*\"neural\" + 0.011*\"memory\" + 0.010*\"feature\" + 0.009*\"action\" + 0.009*\"circular_fingerprint\" + 0.009*\"base\" + 0.008*\"learn\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Model Perplexity and Coherence Score\n",
    "\n",
    "Let's calculate the baseline coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coherence Score: ', 0.26431517844971164)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "First, let's differentiate between model hyperparameters and model parameters :\n",
    "\n",
    "- `Model hyperparameters` can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
    "\n",
    "- `Model parameters` can be thought of as what the model learns during training, such as the weights for each word in a given topic.\n",
    "\n",
    "Now that we have the baseline coherence score for the default LDA model, let's perform a series of sensitivity tests to help determine the following model hyperparameters: \n",
    "- Number of Topics (K)\n",
    "- Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "- Dirichlet hyperparameter beta: Word-Topic Density\n",
    "\n",
    "We'll perform these tests in sequence, one parameter at a time by keeping others constant and run them over the two difference validation corpus sets. We'll use `C_v` as our choice of metric for performance comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function, and iterate it over the range of topics, alpha, and beta parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [47:36<00:00, 10.58s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Training\n",
    "\n",
    "Based on external evaluation (Code to be added from Excel based analysis), train the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  u'0.003*\"cell\" + 0.003*\"current\" + 0.002*\"equipartition\" + 0.002*\"unit\" + 0.002*\"source_separation\" + 0.002*\"density\" + 0.002*\"digital\" + 0.002*\"chip\" + 0.002*\"som\" + 0.001*\"source\"'),\n",
      " (1,\n",
      "  u'0.016*\"network\" + 0.008*\"model\" + 0.008*\"use\" + 0.007*\"training\" + 0.006*\"learn\" + 0.006*\"system\" + 0.006*\"weight\" + 0.006*\"neural\" + 0.006*\"state\" + 0.005*\"train\"'),\n",
      " (2,\n",
      "  u'0.008*\"object\" + 0.005*\"view\" + 0.005*\"formulation\" + 0.004*\"permutation\" + 0.003*\"gain\" + 0.003*\"permutahedron\" + 0.002*\"system\" + 0.002*\"model\" + 0.002*\"sorting_network\" + 0.002*\"current\"'),\n",
      " (3,\n",
      "  u'0.008*\"datum\" + 0.006*\"set\" + 0.005*\"model\" + 0.005*\"matrix\" + 0.004*\"number\" + 0.004*\"use\" + 0.004*\"cluster\" + 0.004*\"rank\" + 0.003*\"perturbation\" + 0.003*\"dimension\"'),\n",
      " (4,\n",
      "  u'0.000*\"color\" + 0.000*\"set\" + 0.000*\"use\" + 0.000*\"network\" + 0.000*\"model\" + 0.000*\"image\" + 0.000*\"function\" + 0.000*\"training\" + 0.000*\"time\" + 0.000*\"point\"'),\n",
      " (5,\n",
      "  u'0.009*\"model\" + 0.007*\"visual\" + 0.006*\"neuron\" + 0.005*\"network\" + 0.005*\"system\" + 0.005*\"input\" + 0.005*\"state\" + 0.004*\"time\" + 0.004*\"function\" + 0.004*\"spike\"'),\n",
      " (6,\n",
      "  u'0.007*\"error\" + 0.006*\"set\" + 0.006*\"term\" + 0.006*\"network\" + 0.005*\"model\" + 0.005*\"cluster\" + 0.004*\"symmetry\" + 0.004*\"partition\" + 0.004*\"theory\" + 0.004*\"target\"'),\n",
      " (7,\n",
      "  u'0.010*\"set\" + 0.009*\"use\" + 0.009*\"model\" + 0.009*\"datum\" + 0.007*\"problem\" + 0.007*\"method\" + 0.007*\"function\" + 0.007*\"sample\" + 0.007*\"learn\" + 0.006*\"feature\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python2.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el24981405141717755681879257859\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el24981405141717755681879257859_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [8, 2, 6, 7, 4, 3, 1, 5], \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 7, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 1, 2, 3, 6, 7, 1, 2, 3, 6, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 6, 1, 2, 3, 4, 5, 1, 2, 3, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 7, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 6, 1, 2, 3, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 7, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 6, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 6, 1, 2, 3, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 4, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 7, 1, 2, 3, 7, 1, 2, 3, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 6, 7, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3], \"Freq\": [0.2094321995973587, 0.4188643991947174, 0.2094321995973587, 0.24905775487422943, 0.24905775487422943, 0.24905775487422943, 0.3436754047870636, 0.4245401918888092, 0.20890073478221893, 0.013477466069161892, 0.4024905860424042, 0.2515566051006317, 0.2515566051006317, 0.07546698302030563, 0.05067885294556618, 0.8742102384567261, 0.06334856897592545, 0.1572011560201645, 0.1572011560201645, 0.1572011560201645, 0.47160348296165466, 0.8644117712974548, 0.07920003682374954, 0.01357714831829071, 0.02941715531051159, 0.01357714831829071, 0.3495309352874756, 0.3495309352874756, 0.1747654676437378, 0.0873827338218689, 0.7355904579162598, 0.11769446730613708, 0.09807872772216797, 0.037269916385412216, 0.009807872585952282, 0.001961574424058199, 0.7709717750549316, 0.058343809098005295, 0.07084605097770691, 0.054176393896341324, 0.04167414829134941, 0.07627665996551514, 0.050851110368967056, 0.8136177659034729, 0.025425555184483528, 0.28402891755104065, 0.28402891755104065, 0.28402891755104065, 0.9310630559921265, 0.029095720499753952, 0.029095720499753952, 0.26567280292510986, 0.26567280292510986, 0.26567280292510986, 0.7771214246749878, 0.14557646214962006, 0.040675777941942215, 0.02568996511399746, 0.008563322015106678, 0.0021408305037766695, 0.815754771232605, 0.0472901314496994, 0.05320139601826668, 0.0236450657248497, 0.05911266431212425, 0.17520731687545776, 0.6334418058395386, 0.14825233817100525, 0.026954971253871918, 0.013477485626935959, 0.06325085461139679, 0.06325085461139679, 0.8222610950469971, 0.04047011584043503, 0.7689322233200073, 0.04047011584043503, 0.1618804633617401, 0.15707318484783173, 0.03490515425801277, 0.7853659391403198, 0.017452577129006386, 0.017452577129006386, 0.045446209609508514, 0.045446209609508514, 0.8634779453277588, 0.24911995232105255, 0.24911995232105255, 0.24911995232105255, 0.28954213857650757, 0.38605618476867676, 0.09651404619216919, 0.09651404619216919, 0.715566873550415, 0.14405284821987152, 0.07672379910945892, 0.05010534077882767, 0.010960543528199196, 0.003131583798676729, 0.29364049434661865, 0.29364049434661865, 0.29364049434661865, 0.06435966491699219, 0.06435966491699219, 0.8366756439208984, 0.29343095421791077, 0.29343095421791077, 0.29343095421791077, 0.19443756341934204, 0.19443756341934204, 0.5185001492500305, 0.06481251865625381, 0.03240625932812691, 0.29337018728256226, 0.29337018728256226, 0.29337018728256226, 0.04124021157622337, 0.9072846174240112, 0.04124021157622337, 0.7969156503677368, 0.022136544808745384, 0.022136544808745384, 0.14942167699337006, 0.011068272404372692, 0.21737398207187653, 0.21737398207187653, 0.21737398207187653, 0.21737398207187653, 0.14128731191158295, 0.14128731191158295, 0.14128731191158295, 0.5651492476463318, 0.42404404282569885, 0.21202202141284943, 0.21202202141284943, 0.26853084564208984, 0.6359941363334656, 0.08479921519756317, 0.014133202843368053, 0.24911566078662872, 0.24911566078662872, 0.24911566078662872, 0.27553659677505493, 0.5510731935501099, 0.13776829838752747, 0.13745784759521484, 0.04581928253173828, 0.7331085205078125, 0.04581928253173828, 0.07943537831306458, 0.7943537831306458, 0.07943537831306458, 0.11218298226594925, 0.11218298226594925, 0.11218298226594925, 0.6730979084968567, 0.029093950986862183, 0.160016730427742, 0.7855366468429565, 0.029093950986862183, 0.3076196610927582, 0.3076196610927582, 0.1538098305463791, 0.1538098305463791, 0.1538098305463791, 0.2838483154773712, 0.2838483154773712, 0.2838483154773712, 0.3677046000957489, 0.07354091852903366, 0.03677045926451683, 0.514786422252655, 0.20949460566043854, 0.4189892113208771, 0.20949460566043854, 0.05518530681729317, 0.8277795910835266, 0.05518530681729317, 0.0993725061416626, 0.0993725061416626, 0.0993725061416626, 0.6956075429916382, 0.2490808367729187, 0.2490808367729187, 0.2490808367729187, 0.14001408219337463, 0.5600563287734985, 0.14001408219337463, 0.14001408219337463, 0.09687065333127975, 0.7265298962593079, 0.09687065333127975, 0.04843532666563988, 0.27291515469551086, 0.27291515469551086, 0.27291515469551086, 0.09129062294960022, 0.09129062294960022, 0.09129062294960022, 0.7303249835968018, 0.1413150280714035, 0.565260112285614, 0.1413150280714035, 0.808242678642273, 0.09263526648283005, 0.05558115988969803, 0.03473822399973869, 0.006947644986212254, 0.002315881662070751, 0.13558828830718994, 0.13558828830718994, 0.13558828830718994, 0.5423531532287598, 0.2941698133945465, 0.16809704899787903, 0.46226686239242554, 0.02101213112473488, 0.02101213112473488, 0.04202426224946976, 0.39246758818626404, 0.4519324004650116, 0.12487605214118958, 0.01783943548798561, 0.005946478806436062, 0.005946478806436062, 0.34770166873931885, 0.02483583241701126, 0.14901499450206757, 0.4470449984073639, 0.03322708234190941, 0.8306770920753479, 0.03322708234190941, 0.03322708234190941, 0.03322708234190941, 0.3824540972709656, 0.1912270486354828, 0.1912270486354828, 0.1912270486354828, 0.13288918137550354, 0.4872603416442871, 0.17718558013439178, 0.044296395033597946, 0.13288918137550354, 0.03368806093931198, 0.9095776677131653, 0.03368806093931198, 0.09559307247400284, 0.04779653623700142, 0.812541127204895, 0.9248578548431396, 0.02601901814341545, 0.0047307307831943035, 0.040211211889982224, 0.0023653653915971518, 0.9291872978210449, 0.025900691747665405, 0.0032375864684581757, 0.03561345115303993, 0.0032375864684581757, 0.08744147419929504, 0.08744147419929504, 0.08744147419929504, 0.786973237991333, 0.6887484192848206, 0.012466034851968288, 0.07791271805763245, 0.14959241449832916, 0.06856319308280945, 0.09656917303800583, 0.09656917303800583, 0.19313834607601166, 0.09656917303800583, 0.48284587264060974, 0.1146732047200203, 0.1146732047200203, 0.1146732047200203, 0.6880391836166382, 0.04244750365614891, 0.4669225215911865, 0.08489500731229782, 0.08489500731229782, 0.2971325218677521, 0.29027989506721497, 0.29027989506721497, 0.29027989506721497, 0.3042851388454437, 0.5821107029914856, 0.06614894419908524, 0.03968936577439308, 0.09177900105714798, 0.7342320084571838, 0.09177900105714798, 0.03154570236802101, 0.06309140473604202, 0.03154570236802101, 0.8517339825630188, 0.19123879075050354, 0.19123879075050354, 0.19123879075050354, 0.3824775815010071, 0.2934952676296234, 0.2934952676296234, 0.2934952676296234, 0.2524121105670929, 0.08413736522197723, 0.08413736522197723, 0.5889616012573242, 0.6608186960220337, 0.11393425613641739, 0.06836055219173431, 0.022786851972341537, 0.045573703944683075, 0.06836055219173431, 0.29022037982940674, 0.29022037982940674, 0.29022037982940674, 0.9438173770904541, 0.02550857700407505, 0.02550857700407505, 0.08488674461841583, 0.7639806866645813, 0.08488674461841583, 0.14819851517677307, 0.5927940607070923, 0.14819851517677307, 0.14819851517677307, 0.639583945274353, 0.02929392084479332, 0.24899832904338837, 0.053705524653196335, 0.004882320296019316, 0.019529281184077263, 0.6723039150238037, 0.07470043748617172, 0.14940087497234344, 0.07470043748617172, 0.9116963744163513, 0.030645256862044334, 0.030645256862044334, 0.015322628431022167, 0.007661314215511084, 0.9220792651176453, 0.023051980882883072, 0.023051980882883072, 0.023051980882883072, 0.8446887135505676, 0.01005581859499216, 0.015083727426826954, 0.11061400175094604, 0.01005581859499216, 0.015083727426826954, 0.316850870847702, 0.158425435423851, 0.158425435423851, 0.158425435423851, 0.316850870847702, 0.1454288512468338, 0.04847628250718117, 0.04847628250718117, 0.7271442413330078, 0.2659560441970825, 0.2659560441970825, 0.2659560441970825, 0.027686292305588722, 0.22149033844470978, 0.7198435664176941, 0.027686292305588722, 0.9554639458656311, 0.027169590815901756, 0.009056529961526394, 0.004528264980763197, 0.12786529958248138, 0.12786529958248138, 0.12786529958248138, 0.5114611983299255, 0.9118292927742004, 0.03507035970687866, 0.03507035970687866, 0.4408506155014038, 0.3347199261188507, 0.14695020020008087, 0.01632780022919178, 0.040819503366947174, 0.01632780022919178, 0.23336713016033173, 0.10607597231864929, 0.021215194836258888, 0.6152406334877014, 0.021215194836258888, 0.2094147801399231, 0.4188295602798462, 0.2094147801399231, 0.9080471396446228, 0.06631805002689362, 0.005101388320326805, 0.01020277664065361, 0.005101388320326805, 0.8060683608055115, 0.08051212131977081, 0.050201673060655594, 0.023680035024881363, 0.03883525729179382, 0.0009472013916820288, 0.969697892665863, 0.013852827250957489, 0.013852827250957489, 0.7739201188087463, 0.06853905320167542, 0.0628274604678154, 0.08281801640987396, 0.011423175223171711, 0.0028557938057929277, 0.07474195957183838, 0.2989678382873535, 0.11211294680833817, 0.48582276701927185, 0.07918607443571091, 0.07918607443571091, 0.7918607592582703, 0.6936853528022766, 0.021020768210291862, 0.10510384291410446, 0.1681661456823349, 0.010510384105145931, 0.010510384105145931, 0.1124727800488472, 0.1124727800488472, 0.1124727800488472, 0.6748366951942444, 0.07940684258937836, 0.7940683960914612, 0.07940684258937836, 0.016393272206187248, 0.016393272206187248, 0.9508097767829895, 0.6502609252929688, 0.13701149821281433, 0.14788542687892914, 0.05219485983252525, 0.008699143305420876, 0.002174785826355219, 0.060857370495796204, 0.060857370495796204, 0.7911458015441895, 0.060857370495796204, 0.16517344117164612, 0.33034688234329224, 0.16517344117164612, 0.16517344117164612, 0.2560184895992279, 0.03200231119990349, 0.03200231119990349, 0.640046238899231, 0.03200231119990349, 0.15967661142349243, 0.3991915285587311, 0.23951491713523865, 0.07983830571174622, 0.7758903503417969, 0.04609249532222748, 0.030728330835700035, 0.007682082708925009, 0.13827748596668243, 0.16436754167079926, 0.16436754167079926, 0.16436754167079926, 0.16436754167079926, 0.3287350833415985, 0.052415214478969574, 0.052415214478969574, 0.31449127197265625, 0.5765673518180847, 0.8886165022850037, 0.03976299613714218, 0.053593602031469345, 0.01210178155452013, 0.005186477676033974, 0.9316587448120117, 0.029114335775375366, 0.029114335775375366, 0.3981710970401764, 0.0995427742600441, 0.0995427742600441, 0.3981710970401764, 0.17107956111431122, 0.17107956111431122, 0.17107956111431122, 0.5132386684417725, 0.24910810589790344, 0.24910810589790344, 0.24910810589790344, 0.43084871768951416, 0.27322113513946533, 0.18915310502052307, 0.10508505254983902, 0.010508505627512932, 0.010508505627512932, 0.24905279278755188, 0.24905279278755188, 0.24905279278755188, 0.15920889377593994, 0.6368355751037598, 0.15920889377593994, 0.2490868717432022, 0.2490868717432022, 0.2490868717432022, 0.12114562839269638, 0.06057281419634819, 0.7874466180801392, 0.679047167301178, 0.08314863592386246, 0.02771621197462082, 0.08314863592386246, 0.11086484789848328, 0.421673446893692, 0.035139452666044235, 0.035139452666044235, 0.07027890533208847, 0.421673446893692, 0.035139452666044235, 0.7520187497138977, 0.09400234371423721, 0.018800469115376472, 0.13160328567028046, 0.645691454410553, 0.06053357571363449, 0.02017785795032978, 0.02017785795032978, 0.22195644676685333, 0.9321936964988708, 0.023500680923461914, 0.023500680923461914, 0.023500680923461914, 0.00783355999737978, 0.9109867215156555, 0.058396585285663605, 0.011679316870868206, 0.27534112334251404, 0.27534112334251404, 0.27534112334251404, 0.29350677132606506, 0.29350677132606506, 0.29350677132606506, 0.3443746864795685, 0.17218734323978424, 0.17218734323978424, 0.3443746864795685, 0.2517041265964508, 0.2517041265964508, 0.2517041265964508, 0.2517041265964508, 0.28048133850097656, 0.28048133850097656, 0.28048133850097656, 0.7394922375679016, 0.07378526031970978, 0.057388532906770706, 0.11805640906095505, 0.011477706953883171, 0.0016396724386140704, 0.7552424073219299, 0.06743235886096954, 0.1348647177219391, 0.01888106018304825, 0.021578354761004448, 0.2683868408203125, 0.06099700927734375, 0.341583251953125, 0.3171844482421875, 0.01219940185546875, 0.7975966930389404, 0.11509623378515244, 0.05451926589012146, 0.018173089250922203, 0.01009616069495678, 0.002019232138991356, 0.10588855296373367, 0.10588855296373367, 0.10588855296373367, 0.6353313326835632, 0.9190353751182556, 0.01955394446849823, 0.01955394446849823, 0.03910788893699646, 0.38162973523139954, 0.5499957799911499, 0.03367321193218231, 0.022448807954788208, 0.17174774408340454, 0.17174774408340454, 0.17174774408340454, 0.5152432322502136, 0.2241002917289734, 0.2241002917289734, 0.2241002917289734, 0.2241002917289734, 0.24909912049770355, 0.24909912049770355, 0.24909912049770355, 0.2748180627822876, 0.2748180627822876, 0.2748180627822876, 0.7961524724960327, 0.10483146458864212, 0.0878317654132843, 0.007083206903189421, 0.002833282807841897, 0.2902473509311676, 0.2902473509311676, 0.2902473509311676, 0.06796619296073914, 0.835013210773468, 0.08738510310649872, 0.009709456004202366, 0.009709456004202366, 0.1444491595029831, 0.1444491595029831, 0.1444491595029831, 0.5777966380119324, 0.5569162368774414, 0.017403632402420044, 0.3132653832435608, 0.06961452960968018, 0.03480726480484009, 0.008701816201210022, 0.6333362460136414, 0.17720288038253784, 0.13454292714595795, 0.022970745339989662, 0.024611512199044228, 0.006563069764524698, 0.6312787532806396, 0.12756410241127014, 0.12429323047399521, 0.10466798394918442, 0.009812623262405396, 0.003270874498412013, 0.01885661669075489, 0.9428308606147766, 0.01885661669075489, 0.032412149012088776, 0.1296485960483551, 0.7778915762901306, 0.032412149012088776, 0.09192834049463272, 0.18385668098926544, 0.6664804816246033, 0.04596417024731636, 0.15906722843647003, 0.6362689137458801, 0.15906722843647003, 0.23916827142238617, 0.23916827142238617, 0.23916827142238617, 0.23916827142238617, 0.7736784815788269, 0.09153379499912262, 0.07191941142082214, 0.04576689749956131, 0.013076256029307842, 0.002179376082494855, 0.07490020990371704, 0.07490020990371704, 0.8239023089408875, 0.7205567359924316, 0.03948256000876427, 0.009870640002191067, 0.09870640188455582, 0.019741280004382133, 0.10857703536748886, 0.9186019897460938, 0.03280721604824066, 0.03280721604824066, 0.7387264966964722, 0.11179540306329727, 0.10193110257387161, 0.03836116939783096, 0.007672233507037163, 0.0010960333747789264, 0.11126912385225296, 0.11126912385225296, 0.11126912385225296, 0.667614758014679, 0.4243871569633484, 0.22336167097091675, 0.11168083548545837, 0.08934466540813446, 0.022336166352033615, 0.1340170055627823, 0.8954303860664368, 0.031817324459552765, 0.05908931419253349, 0.004545331932604313, 0.004545331932604313, 0.28051629662513733, 0.28051629662513733, 0.28051629662513733, 0.6043255925178528, 0.10664569586515427, 0.04443570598959923, 0.23995280265808105, 0.00888714101165533, 0.39740172028541565, 0.05677167326211929, 0.11354334652423859, 0.39740172028541565, 0.7376745343208313, 0.09770523011684418, 0.09119155257940292, 0.052109457552433014, 0.019541047513484955, 0.0032568410970270634, 0.5518007874488831, 0.38243621587753296, 0.054633744060993195, 0.010926748625934124, 0.005463374312967062, 0.8846347332000732, 0.07961712777614594, 0.026539040729403496, 0.004423173610121012, 0.004423173610121012, 0.12750157713890076, 0.12750157713890076, 0.12750157713890076, 0.6375078558921814, 0.29338228702545166, 0.29338228702545166, 0.29338228702545166, 0.16909214854240417, 0.05636404827237129, 0.11272809654474258, 0.6200045347213745, 0.9180818796157837, 0.022668687626719475, 0.011334343813359737, 0.034003034234046936, 0.011334343813359737, 0.21464936435222626, 0.21464936435222626, 0.21464936435222626, 0.4292987287044525, 0.18371684849262238, 0.18371684849262238, 0.18371684849262238, 0.36743369698524475, 0.07087911665439606, 0.8505493998527527, 0.07087911665439606, 0.29340916872024536, 0.29340916872024536, 0.29340916872024536, 0.2490493655204773, 0.2490493655204773, 0.2490493655204773, 0.06243930757045746, 0.06243930757045746, 0.06243930757045746, 0.8117110133171082, 0.06241295859217644, 0.06241295859217644, 0.06241295859217644, 0.811368465423584, 0.09602902829647064, 0.09602902829647064, 0.09602902829647064, 0.7682322263717651, 0.10697437822818756, 0.7488206624984741, 0.10697437822818756, 0.1808219999074936, 0.5424659848213196, 0.1808219999074936, 0.08774293959140778, 0.7019435167312622, 0.08774293959140778, 0.08774293959140778, 0.7409064769744873, 0.16221028566360474, 0.07672108709812164, 0.006576092913746834, 0.00438406178727746, 0.00876812357455492, 0.21460461616516113, 0.21460461616516113, 0.21460461616516113, 0.42920923233032227, 0.3623085021972656, 0.2608621120452881, 0.289846807718277, 0.04347702115774155, 0.04347702115774155, 0.29023227095603943, 0.29023227095603943, 0.29023227095603943, 0.1587793380022049, 0.6351173520088196, 0.1587793380022049, 0.4700249433517456, 0.15667498111724854, 0.15667498111724854, 0.15667498111724854, 0.27547621726989746, 0.5509524345397949, 0.13773810863494873, 0.1299804002046585, 0.1299804002046585, 0.1299804002046585, 0.6499019861221313, 0.3857717216014862, 0.3418230414390564, 0.2539256811141968, 0.007324779871851206, 0.004883186426013708, 0.004883186426013708, 0.07198788225650787, 0.2879515290260315, 0.14397576451301575, 0.43192729353904724, 0.16841593384742737, 0.06736637651920319, 0.7073469161987305, 0.03368318825960159, 0.13240765035152435, 0.06620382517576218, 0.06620382517576218, 0.662038266658783, 0.29022568464279175, 0.29022568464279175, 0.29022568464279175, 0.9502171277999878, 0.027149060741066933, 0.00904968660324812, 0.00452484330162406, 0.00452484330162406, 0.29345768690109253, 0.29345768690109253, 0.29345768690109253, 0.2934085726737976, 0.2934085726737976, 0.2934085726737976, 0.29021787643432617, 0.29021787643432617, 0.29021787643432617, 0.8506312966346741, 0.013222248293459415, 0.013222248293459415, 0.11459282040596008, 0.004407416097819805, 0.9555708765983582, 0.012095834128558636, 0.012095834128558636, 0.016127778217196465, 0.004031944554299116, 0.9385932087898254, 0.027605682611465454, 0.027605682611465454, 0.2491367906332016, 0.2491367906332016, 0.2491367906332016, 0.09928420186042786, 0.7942736148834229, 0.04964210093021393, 0.07499336451292038, 0.824927031993866, 0.07499336451292038, 0.0626198947429657, 0.0626198947429657, 0.1252397894859314, 0.6888188719749451, 0.07941493391990662, 0.07941493391990662, 0.07941493391990662, 0.7147343754768372, 0.22634197771549225, 0.6425191760063171, 0.1095203161239624, 0.007301354315131903, 0.007301354315131903, 0.2934907376766205, 0.2934907376766205, 0.2934907376766205, 0.2839149534702301, 0.2839149534702301, 0.2839149534702301, 0.6988481879234314, 0.19842492043972015, 0.06541480869054794, 0.025075675919651985, 0.009812220931053162, 0.0010902468347921968, 0.6485811471939087, 0.23584768176078796, 0.08423131704330444, 0.02246168442070484, 0.00842313189059496, 0.8591222167015076, 0.023959584534168243, 0.020536785945296288, 0.08556994050741196, 0.0068455953150987625, 0.0034227976575493813, 0.23747223615646362, 0.059368059039115906, 0.059368059039115906, 0.6530486345291138, 0.5843222737312317, 0.048026490956544876, 0.33618542551994324, 0.024013245478272438, 0.008004414848983288, 0.6971470713615417, 0.16148604452610016, 0.0905897319316864, 0.03150947391986847, 0.003938684239983559, 0.011816051788628101, 0.17857766151428223, 0.08928883075714111, 0.35715532302856445, 0.08928883075714111, 0.26786649227142334, 0.24562713503837585, 0.24562713503837585, 0.24562713503837585, 0.24562713503837585, 0.09177997708320618, 0.09177997708320618, 0.09177997708320618, 0.7342398166656494, 0.06739775091409683, 0.13479550182819366, 0.7413752675056458, 0.38501155376434326, 0.02026376686990261, 0.44580286741256714, 0.13171447813510895, 0.010131883434951305, 0.010131883434951305, 0.9212134480476379, 0.027094513177871704, 0.027094513177871704, 0.027094513177871704, 0.14297214150428772, 0.14297214150428772, 0.14297214150428772, 0.5718885660171509, 0.1432940661907196, 0.1432940661907196, 0.1432940661907196, 0.5731762647628784, 0.9264206290245056, 0.020702136680483818, 0.01552660297602415, 0.020702136680483818, 0.01552660297602415, 0.0051755341701209545, 0.19248752295970917, 0.09624376147985458, 0.09624376147985458, 0.5774625539779663, 0.14203625917434692, 0.5681450366973877, 0.14203625917434692, 0.2005244642496109, 0.2005244642496109, 0.2005244642496109, 0.2005244642496109, 0.2005244642496109, 0.24570147693157196, 0.24570147693157196, 0.24570147693157196, 0.24570147693157196, 0.9328881502151489, 0.01636645942926407, 0.01636645942926407, 0.01636645942926407, 0.03273291885852814, 0.5212167501449585, 0.11401616036891937, 0.29318439960479736, 0.06515209376811981, 0.0054293409921228886, 0.9381039142608643, 0.02039356343448162, 0.02039356343448162, 0.02039356343448162, 0.02039356343448162, 0.9060529470443726, 0.00995662622153759, 0.01991325244307518, 0.0497831292450428, 0.8164335489273071, 0.01535611692816019, 0.08957734704017639, 0.01023741066455841, 0.06654316931962967, 0.0025593526661396027, 0.2616560161113739, 0.6167606711387634, 0.08410372585058212, 0.0186897162348032, 0.0093448581174016, 0.03798449784517288, 0.03798449784517288, 0.9116278886795044, 0.8482391834259033, 0.07970830798149109, 0.03331093490123749, 0.027362553402781487, 0.010707085952162743, 0.0011896762298420072, 0.8956782817840576, 0.07071144878864288, 0.007856827229261398, 0.007856827229261398, 0.023570481687784195, 0.24908585846424103, 0.24908585846424103, 0.24908585846424103, 0.2933041453361511, 0.2933041453361511, 0.2933041453361511, 0.9176559448242188, 0.012570628896355629, 0.050282515585422516, 0.012570628896355629, 0.012570628896355629, 0.8381302952766418, 0.1229257732629776, 0.011175070889294147, 0.011175070889294147, 0.011175070889294147, 0.050848741084337234, 0.8644285798072815, 0.050848741084337234, 0.6314558386802673, 0.16579319536685944, 0.14416800439357758, 0.03460032120347023, 0.01946268044412136, 0.003604199970141053, 0.11470359563827515, 0.802925169467926, 0.05735179781913757, 0.044057395309209824, 0.8811479210853577, 0.044057395309209824, 0.12786804139614105, 0.6393401622772217, 0.12786804139614105, 0.20945630967617035, 0.4189126193523407, 0.20945630967617035, 0.04255913943052292, 0.8937419056892395, 0.04255913943052292, 0.24803316593170166, 0.6338625550270081, 0.0964573472738266, 0.23614631593227386, 0.07871543616056442, 0.07871543616056442, 0.5510080456733704, 0.07139596343040466, 0.07139596343040466, 0.07139596343040466, 0.7853555679321289, 0.1275090128183365, 0.1275090128183365, 0.1275090128183365, 0.6375450491905212, 0.539769172668457, 0.20562633872032166, 0.17992304265499115, 0.025703292340040207, 0.025703292340040207, 0.025703292340040207, 0.33547085523605347, 0.4472944736480713, 0.11182361841201782, 0.05591180920600891, 0.23973442614078522, 0.5458031296730042, 0.13732360303401947, 0.06749804317951202, 0.0046550375409424305, 0.0046550375409424305, 0.34973156452178955, 0.43650707602500916, 0.17881013453006744, 0.021036485210061073, 0.010518242605030537, 0.005259121302515268, 0.02629951760172844, 0.40952104330062866, 0.5184761881828308, 0.041327811777591705, 0.003757074009627104, 0.5719910264015198, 0.30531951785087585, 0.08116088807582855, 0.007729608099907637, 0.030918432399630547, 0.6404693126678467, 0.15342718362808228, 0.10169010609388351, 0.05887322127819061, 0.04103285074234009, 0.003568073967471719, 0.5227496027946472, 0.11549118906259537, 0.21882541477680206, 0.0060784840025007725, 0.030392419546842575, 0.1033342257142067, 0.6637407541275024, 0.12068014591932297, 0.060340072959661484, 0.12068014591932297, 0.9447398781776428, 0.030312510207295418, 0.005052085034549236, 0.015156255103647709, 0.005052085034549236, 0.005052085034549236, 0.767016589641571, 0.05900127440690994, 0.07866836339235306, 0.01311139389872551, 0.07866836339235306, 0.8312885761260986, 0.09048039466142654, 0.050895221531391144, 0.0197925865650177, 0.0028275123331695795, 0.0028275123331695795, 0.24569085240364075, 0.24569085240364075, 0.24569085240364075, 0.24569085240364075, 0.5259774327278137, 0.2922096848487854, 0.05844193696975708, 0.05844193696975708, 0.05844193696975708, 0.29340213537216187, 0.29340213537216187, 0.29340213537216187, 0.649263322353363, 0.08853591233491898, 0.029511969536542892, 0.059023939073085785, 0.029511969536542892, 0.11804787814617157, 0.90973299741745, 0.012428046204149723, 0.06711144745349884, 0.0074568274430930614, 0.002485609147697687, 0.931073784828186, 0.030034637078642845, 0.030034637078642845, 0.030034637078642845, 0.6875658631324768, 0.13966181874275208, 0.07520251721143723, 0.06983090937137604, 0.0214864332228899, 0.005371608305722475, 0.16426537930965424, 0.16426537930965424, 0.08213268965482712, 0.16426537930965424, 0.4106634557247162, 0.08213268965482712, 0.1816760152578354, 0.0660640075802803, 0.7101880311965942, 0.03303200379014015, 0.2934589087963104, 0.2934589087963104, 0.2934589087963104, 0.4177056849002838, 0.43008217215538025, 0.12376464903354645, 0.015470581129193306, 0.006188232451677322, 0.006188232451677322, 0.2935201823711395, 0.2935201823711395, 0.2935201823711395, 0.10151572525501251, 0.10151572525501251, 0.10151572525501251, 0.710610032081604, 0.09805972874164581, 0.09805972874164581, 0.09805972874164581, 0.6864181160926819, 0.24903108179569244, 0.24903108179569244, 0.24903108179569244, 0.12894926965236664, 0.12894926965236664, 0.12894926965236664, 0.6447463631629944, 0.3356100022792816, 0.18071308732032776, 0.20652924478054047, 0.18071308732032776, 0.07744846493005753, 0.16148771345615387, 0.16148771345615387, 0.16148771345615387, 0.4844631552696228, 0.5894284844398499, 0.024905428290367126, 0.008301809430122375, 0.35697782039642334, 0.008301809430122375, 0.008301809430122375, 0.008301809430122375, 0.07170144468545914, 0.07170144468545914, 0.5736115574836731, 0.215104341506958, 0.14941367506980896, 0.07470683753490448, 0.07470683753490448, 0.6723615527153015, 0.15255199372768402, 0.15255199372768402, 0.15255199372768402, 0.6102079749107361, 0.06165158748626709, 0.18495476245880127, 0.7089932560920715, 0.030825793743133545, 0.6722325086593628, 0.18602660298347473, 0.059190280735492706, 0.07398784905672073, 0.00845575425773859, 0.0021139385644346476, 0.10965939611196518, 0.10965939611196518, 0.10965939611196518, 0.10965939611196518, 0.5482969880104065, 0.44620615243911743, 0.044620614498853683, 0.08924122899770737, 0.2454133927822113, 0.17848245799541473, 0.24990975856781006, 0.40610337257385254, 0.015619359910488129, 0.031238719820976257, 0.2811484932899475, 0.08468154817819595, 0.7621338963508606, 0.08468154817819595, 0.11285984516143799, 0.11285984516143799, 0.11285984516143799, 0.6771590709686279, 0.9268261194229126, 0.021554095670580864, 0.021554095670580864, 0.031202657148241997, 0.031202657148241997, 0.9048770070075989, 0.031202657148241997, 0.05235568434000015, 0.05235568434000015, 0.8376909494400024, 0.8126400709152222, 0.12537875771522522, 0.04024503007531166, 0.015478858724236488, 0.00619154330343008, 0.00309577165171504, 0.08397142589092255, 0.08397142589092255, 0.7557428479194641, 0.11952325701713562, 0.11952325701713562, 0.11952325701713562, 0.5976163148880005, 0.24381375312805176, 0.16681993007659912, 0.5389567017555237, 0.03849690780043602, 0.061501313000917435, 0.061501313000917435, 0.061501313000917435, 0.7995170950889587, 0.4352641701698303, 0.38344699144363403, 0.12954290211200714, 0.04663544520735741, 0.005181716289371252, 0.40434104204177856, 0.05054263025522232, 0.05054263025522232, 0.505426287651062, 0.29020974040031433, 0.29020974040031433, 0.29020974040031433, 0.6036804914474487, 0.01117926836013794, 0.36332622170448303, 0.00558963418006897, 0.01676890254020691, 0.0644528865814209, 0.0644528865814209, 0.8378875255584717, 0.9509441256523132, 0.023193757981061935, 0.023193757981061935, 0.7958542108535767, 0.12004504352807999, 0.04001501575112343, 0.031122788786888123, 0.010003753937780857, 0.002223056275397539, 0.6071977615356445, 0.26716700196266174, 0.0850076824426651, 0.012143954634666443, 0.012143954634666443, 0.012143954634666443, 0.5823025703430176, 0.2495582401752472, 0.0831860825419426, 0.0831860825419426, 0.15759429335594177, 0.4727828800678253, 0.15759429335594177, 0.15759429335594177, 0.19427837431430817, 0.757685661315918, 0.019427837803959846, 0.019427837803959846, 0.20419920980930328, 0.10209960490465164, 0.10209960490465164, 0.612597644329071, 0.17279918491840363, 0.5183975100517273, 0.17279918491840363, 0.2491369992494583, 0.2491369992494583, 0.2491369992494583, 0.13334904611110687, 0.13334904611110687, 0.13334904611110687, 0.5333961844444275, 0.06378146260976791, 0.7653775811195374, 0.06378146260976791, 0.06378146260976791, 0.8567185997962952, 0.08142367005348206, 0.0212409570813179, 0.0177007969468832, 0.0177007969468832, 0.6562153100967407, 0.013671153225004673, 0.027342306450009346, 0.013671153225004673, 0.28709420561790466, 0.24911624193191528, 0.24911624193191528, 0.24911624193191528, 0.0734793096780777, 0.0734793096780777, 0.8082724213600159, 0.0734793096780777, 0.5870539546012878, 0.08386485278606415, 0.041932426393032074, 0.020966213196516037, 0.2306283414363861, 0.020966213196516037, 0.5267435908317566, 0.03292147442698479, 0.03292147442698479, 0.03292147442698479, 0.39505767822265625, 0.028081361204385757, 0.8143594861030579, 0.1404068022966385, 0.2490972876548767, 0.2490972876548767, 0.2490972876548767, 0.249068021774292, 0.249068021774292, 0.249068021774292, 0.9313980340957642, 0.022717025130987167, 0.022717025130987167, 0.7666981220245361, 0.03304733335971832, 0.03965679928660393, 0.1520177274942398, 0.006609466392546892, 0.006609466392546892, 0.2274467945098877, 0.2274467945098877, 0.2274467945098877, 0.2274467945098877, 0.277873158454895, 0.1389365792274475, 0.1389365792274475, 0.41680970788002014, 0.39411449432373047, 0.13137149810791016, 0.13137149810791016, 0.39411449432373047, 0.0962616354227066, 0.0962616354227066, 0.0962616354227066, 0.7700930833816528, 0.6097095608711243, 0.059004150331020355, 0.01966805011034012, 0.23601660132408142, 0.01966805011034012, 0.059004150331020355, 0.08148016780614853, 0.16296033561229706, 0.08148016780614853, 0.6518413424491882, 0.5269559621810913, 0.221133291721344, 0.2070184051990509, 0.014114891178905964, 0.014114891178905964, 0.014114891178905964, 0.15864162147045135, 0.6345664858818054, 0.15864162147045135, 0.1415126621723175, 0.56605064868927, 0.1415126621723175, 0.12937644124031067, 0.17558230459690094, 0.4990234076976776, 0.12013526260852814, 0.0554470457136631, 0.018482347950339317, 0.6989104151725769, 0.15199604630470276, 0.09906885027885437, 0.03664190322160721, 0.01085686031728983, 0.0013571075396612287, 0.29360073804855347, 0.29360073804855347, 0.29360073804855347, 0.33745306730270386, 0.11248435080051422, 0.11248435080051422, 0.33745306730270386, 0.29352042078971863, 0.29352042078971863, 0.29352042078971863, 0.11007822304964066, 0.7705475687980652, 0.05503911152482033, 0.06068336218595505, 0.8495671153068542, 0.06068336218595505, 0.6440476179122925, 0.09721473604440689, 0.048607368022203445, 0.012151842005550861, 0.1822776198387146, 0.0906294584274292, 0.0453147292137146, 0.0453147292137146, 0.8156651258468628, 0.20768849551677704, 0.20768849551677704, 0.20768849551677704, 0.20768849551677704, 0.25560539960861206, 0.5894573330879211, 0.07824654877185822, 0.03651505336165428, 0.026082182303071022, 0.010432872921228409, 0.9507632255554199, 0.02343946322798729, 0.01904456317424774, 0.002929932903498411, 0.002929932903498411, 0.0014649664517492056, 0.19289946556091309, 0.19289946556091309, 0.19289946556091309, 0.19289946556091309, 0.1197306215763092, 0.1197306215763092, 0.1197306215763092, 0.7183837294578552, 0.471788614988327, 0.3476337194442749, 0.1489858776330948, 0.42989376187324524, 0.17912240326404572, 0.23285911977291107, 0.0716489627957344, 0.0179122406989336, 0.0716489627957344, 0.05438088998198509, 0.16314266622066498, 0.05438088998198509, 0.7069515585899353, 0.8389654159545898, 0.08571473509073257, 0.03636382520198822, 0.02857157774269581, 0.007792248390614986, 0.0025974162854254246, 0.7006680369377136, 0.14597250521183014, 0.10218075662851334, 0.03503340110182762, 0.011677800677716732, 0.002919450169429183, 0.13714180886745453, 0.13714180886745453, 0.13714180886745453, 0.13714180886745453, 0.4114254415035248, 0.226052924990654, 0.452105849981308, 0.226052924990654, 0.29366829991340637, 0.29366829991340637, 0.29366829991340637, 0.2935032248497009, 0.2935032248497009, 0.2935032248497009, 0.023491455242037773, 0.07047437131404877, 0.8691838979721069, 0.023491455242037773, 0.475037157535553, 0.4598763883113861, 0.04042869433760643, 0.005053586792200804, 0.015160759910941124, 0.2068583071231842, 0.2068583071231842, 0.2068583071231842, 0.2068583071231842, 0.7997502684593201, 0.0837988629937172, 0.03905189409852028, 0.050442032516002655, 0.023593854159116745, 0.0016271623317152262, 0.41380077600479126, 0.20690038800239563, 0.20690038800239563, 0.24603673815727234, 0.24603673815727234, 0.24603673815727234, 0.24603673815727234, 0.7039321064949036, 0.12848469614982605, 0.1052480936050415, 0.047840043902397156, 0.010934866964817047, 0.0027337167412042618, 0.4209155738353729, 0.34991776943206787, 0.20285087823867798, 0.015213815495371819, 0.005071271676570177, 0.14171826839447021, 0.5668730735778809, 0.14171826839447021, 0.42864131927490234, 0.42864131927490234, 0.08572826534509659, 0.0747838094830513, 0.0747838094830513, 0.8226218819618225, 0.038663722574710846, 0.038663722574710846, 0.8506019115447998, 0.038663722574710846, 0.28422021865844727, 0.28422021865844727, 0.28422021865844727, 0.2933788299560547, 0.2933788299560547, 0.2933788299560547, 0.24913524091243744, 0.24913524091243744, 0.24913524091243744, 0.07069138437509537, 0.8482966423034668, 0.07069138437509537, 0.1937706470489502, 0.1937706470489502, 0.1937706470489502, 0.1937706470489502, 0.1937706470489502, 0.11776699125766754, 0.11776699125766754, 0.11776699125766754, 0.11776699125766754, 0.5888349413871765, 0.8936103582382202, 0.0484904870390892, 0.04156327247619629, 0.006927212234586477, 0.006927212234586477, 0.5508886575698853, 0.1377221643924713, 0.1377221643924713, 0.1377221643924713, 0.21475480496883392, 0.21475480496883392, 0.21475480496883392, 0.42950960993766785, 0.03740725293755531, 0.09351813793182373, 0.851015031337738, 0.009351813234388828, 0.12012221664190292, 0.12012221664190292, 0.12012221664190292, 0.6006110906600952, 0.2490866631269455, 0.2490866631269455, 0.2490866631269455, 0.41951432824134827, 0.20063729584217072, 0.03647950664162636, 0.3100758194923401, 0.01823975332081318, 0.41879332065582275, 0.3552068769931793, 0.21487824618816376, 0.0065779052674770355, 0.002192635089159012, 0.27284303307533264, 0.27284303307533264, 0.13642151653766632, 0.29359808564186096, 0.29359808564186096, 0.29359808564186096, 0.03539782762527466, 0.01769891381263733, 0.8849456906318665, 0.05309674143791199, 0.8937996625900269, 0.0788646787405014, 0.01577293500304222, 0.005257645156234503, 0.17262078821659088, 0.02877013199031353, 0.7767935395240784, 0.02877013199031353, 0.0846698209643364, 0.7620283961296082, 0.0846698209643364, 0.7188934087753296, 0.018433164805173874, 0.09216582030057907, 0.16589847207069397, 0.11776477098464966, 0.7654710412025452, 0.05888238549232483, 0.12000386416912079, 0.7800251245498657, 0.060001932084560394, 0.20950274169445038, 0.41900548338890076, 0.20950274169445038, 0.13940340280532837, 0.6970170736312866, 0.10455255955457687, 0.03485085070133209, 0.22285601496696472, 0.11142800748348236, 0.22285601496696472, 0.44571202993392944, 0.04283565655350685, 0.7282061576843262, 0.04283565655350685, 0.12850697338581085, 0.04283565655350685, 0.03771597892045975, 0.9051835536956787, 0.03771597892045975, 0.020446913316845894, 0.020446913316845894, 0.04089382663369179, 0.879217267036438, 0.020446913316845894, 0.09172537922859192, 0.09172537922859192, 0.09172537922859192, 0.7338030338287354, 0.018290165811777115, 0.20119182765483856, 0.7681869268417358, 0.26596760749816895, 0.4196920096874237, 0.26596760749816895, 0.031720906496047974, 0.004880139604210854, 0.012200349010527134, 0.2490602731704712, 0.2490602731704712, 0.2490602731704712, 0.29342183470726013, 0.29342183470726013, 0.29342183470726013, 0.5302372574806213, 0.13134318590164185, 0.14107230305671692, 0.18971793353557587, 0.7767104506492615, 0.14405156672000885, 0.05255935341119766, 0.025306355208158493, 0.0019466426456347108, 0.0019466426456347108, 0.08559916168451309, 0.7703924179077148, 0.08559916168451309, 0.06452007591724396, 0.688214123249054, 0.19356021285057068, 0.021506691351532936, 0.6115263104438782, 0.1332375854253769, 0.03416348248720169, 0.20839723944664001, 0.010249044746160507, 0.07168865948915482, 0.07168865948915482, 0.07168865948915482, 0.7885752320289612, 0.2935827374458313, 0.2935827374458313, 0.2935827374458313, 0.1511198729276657, 0.1511198729276657, 0.1511198729276657, 0.4533596336841583, 0.6676738262176514, 0.04701928421854973, 0.07052892446517944, 0.19748099148273468, 0.009403856471180916, 0.29022371768951416, 0.29022371768951416, 0.29022371768951416, 0.617605447769165, 0.17838603258132935, 0.14090996980667114, 0.05546456575393677, 0.005996169056743383, 0.0014990422641858459, 0.20947813987731934, 0.41895627975463867, 0.20947813987731934, 0.06441144645214081, 0.06441144645214081, 0.8373487591743469, 0.12131742388010025, 0.060658711940050125, 0.7885632514953613, 0.9674925804138184, 0.011656536720693111, 0.011656536720693111, 0.011656536720693111, 0.26592734456062317, 0.06648183614015579, 0.06648183614015579, 0.5983365178108215, 0.49059104919433594, 0.41127392649650574, 0.0734417736530304, 0.017626024782657623, 0.005875341594219208, 0.002937670797109604, 0.06087054684758186, 0.8521876335144043, 0.06087054684758186, 0.6240434050559998, 0.3169225752353668, 0.021237079054117203, 0.031038807705044746, 0.004900864325463772, 0.0016336215194314718, 0.08789002150297165, 0.615230143070221, 0.08789002150297165, 0.08789002150297165, 0.15109144151210785, 0.15109144151210785, 0.15109144151210785, 0.45327433943748474, 0.9146350026130676, 0.028582343831658363, 0.028582343831658363, 0.028582343831658363, 0.23556183278560638, 0.47112366557121277, 0.22434461116790771, 0.044868919998407364, 0.01682584546506405, 0.0056086149998009205, 0.906710684299469, 0.03022368997335434, 0.03022368997335434, 0.03022368997335434, 0.2834280729293823, 0.2834280729293823, 0.2834280729293823, 0.21475914120674133, 0.21475914120674133, 0.21475914120674133, 0.42951828241348267, 0.7107881307601929, 0.17083320021629333, 0.0678756907582283, 0.02974327839910984, 0.017540907487273216, 0.003050592727959156, 0.29344189167022705, 0.29344189167022705, 0.29344189167022705, 0.676412045955658, 0.16408014297485352, 0.12222295999526978, 0.025114307180047035, 0.008371436037123203, 0.0016742871375754476, 0.9554905891418457, 0.017694270238280296, 0.008847135119140148, 0.008847135119140148, 0.008847135119140148, 0.6954294443130493, 0.2223481982946396, 0.05440434440970421, 0.00946162547916174, 0.011827032081782818, 0.00946162547916174, 0.27491283416748047, 0.27491283416748047, 0.27491283416748047, 0.24581606686115265, 0.24581606686115265, 0.24581606686115265, 0.24581606686115265, 0.3568855822086334, 0.16905106604099274, 0.23479315638542175, 0.028175178915262222, 0.10330899059772491, 0.10330899059772491, 0.14906933903694153, 0.29813867807388306, 0.14906933903694153, 0.29813867807388306, 0.08461868017911911, 0.7615681290626526, 0.08461868017911911, 0.12918134033679962, 0.04306044429540634, 0.7804705500602722, 0.032295335084199905, 0.005382555536925793, 0.005382555536925793, 0.07480522990226746, 0.8228574991226196, 0.07480522990226746, 0.02735847979784012, 0.5198110938072205, 0.3283017575740814, 0.02735847979784012, 0.08207543939352036, 0.02735847979784012, 0.26030245423316956, 0.26030245423316956, 0.26030245423316956, 0.15695106983184814, 0.15695106983184814, 0.15695106983184814, 0.47085320949554443, 0.07283952087163925, 0.07283952087163925, 0.07283952087163925, 0.7283951640129089, 0.2806374430656433, 0.2806374430656433, 0.2806374430656433, 0.086382657289505, 0.7774438858032227, 0.086382657289505, 0.2831271290779114, 0.514499843120575, 0.08524258434772491, 0.11264198273420334, 0.0030443777795881033, 0.2590726912021637, 0.2590726912021637, 0.2590726912021637, 0.05889100581407547, 0.05889100581407547, 0.824474036693573], \"Term\": [\"abundance\", \"abundance\", \"abundance\", \"accident\", \"accident\", \"accident\", \"action\", \"action\", \"action\", \"action\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"agent\", \"agent\", \"agent\", \"aileron\", \"aileron\", \"aileron\", \"aileron\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"align\", \"align\", \"align\", \"align\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"animal\", \"animal\", \"animal\", \"animal\", \"anisotropic\", \"anisotropic\", \"anisotropic\", \"anomaly\", \"anomaly\", \"anomaly\", \"apap\", \"apap\", \"apap\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"asymmetry\", \"asymmetry\", \"asymmetry\", \"atom\", \"atom\", \"atom\", \"atom\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"auditory\", \"auditory\", \"auditory\", \"awash\", \"awash\", \"awash\", \"axis\", \"axis\", \"axis\", \"axis\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"bauer\", \"bauer\", \"bauer\", \"bdmm\", \"bdmm\", \"bdmm\", \"bend\", \"bend\", \"bend\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"binaryconnect\", \"binaryconnect\", \"binaryconnect\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"birkhoff\", \"birkhoff\", \"birkhoff\", \"birkhoff\", \"birkhoff_polytope\", \"birkhoff_polytope\", \"birkhoff_polytope\", \"birkhoff_polytope\", \"blind_separation\", \"blind_separation\", \"blind_separation\", \"block\", \"block\", \"block\", \"block\", \"bluer\", \"bluer\", \"bluer\", \"blur\", \"blur\", \"blur\", \"body\", \"body\", \"body\", \"body\", \"bond\", \"bond\", \"bond\", \"bootc\", \"bootc\", \"bootc\", \"bootc\", \"brain\", \"brain\", \"brain\", \"brain\", \"branch\", \"branch\", \"branch\", \"branch\", \"branch\", \"branched\", \"branched\", \"branched\", \"break\", \"break\", \"break\", \"break\", \"bright\", \"bright\", \"bright\", \"brnn\", \"brnn\", \"brnn\", \"bwgp\", \"bwgp\", \"bwgp\", \"bwgp\", \"cal\", \"cal\", \"cal\", \"california_institute\", \"california_institute\", \"california_institute\", \"california_institute\", \"camera\", \"camera\", \"camera\", \"camera\", \"cancellation\", \"cancellation\", \"cancellation\", \"capped_regularization\", \"capped_regularization\", \"capped_regularization\", \"capped_regularization\", \"card\", \"card\", \"card\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cdn\", \"cdn\", \"cdn\", \"cdn\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"child\", \"child\", \"child\", \"child\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chow\", \"chow\", \"chow\", \"chow\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circular_fingerprint\", \"circular_fingerprint\", \"circular_fingerprint\", \"city\", \"city\", \"city\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"clique_expansion\", \"clique_expansion\", \"clique_expansion\", \"clique_expansion\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"coherence\", \"coherence\", \"coherence\", \"coherence\", \"coherence\", \"coherence_parameter\", \"coherence_parameter\", \"coherence_parameter\", \"coherence_parameter\", \"coherent\", \"coherent\", \"coherent\", \"coherent\", \"coherent\", \"coincidence\", \"coincidence\", \"coincidence\", \"color\", \"color\", \"color\", \"color\", \"color_constancy\", \"color_constancy\", \"color_constancy\", \"committee\", \"committee\", \"committee\", \"committee\", \"comparator\", \"comparator\", \"comparator\", \"comparator\", \"componentwise\", \"componentwise\", \"componentwise\", \"compressive\", \"compressive\", \"compressive\", \"compressive\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"concurrently\", \"concurrently\", \"concurrently\", \"confusion\", \"confusion\", \"confusion\", \"conserve\", \"conserve\", \"conserve\", \"constancy\", \"constancy\", \"constancy\", \"constancy\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"contour\", \"contour\", \"contour\", \"contour\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex_hull\", \"convex_hull\", \"convex_hull\", \"convex_hull\", \"convex_hull\", \"convex_relaxation\", \"convex_relaxation\", \"convex_relaxation\", \"convex_relaxation\", \"conveyor\", \"conveyor\", \"conveyor\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cost\", \"cost\", \"cost\", \"cost\", \"creep\", \"creep\", \"creep\", \"creep\", \"crf\", \"crf\", \"crf\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"darkness\", \"darkness\", \"darkness\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"decision_maker\", \"decision_maker\", \"decision_maker\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"delay\", \"delay\", \"delay\", \"delay\", \"dendritic\", \"dendritic\", \"dendritic\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density_estimator\", \"density_estimator\", \"density_estimator\", \"density_estimator\", \"detect_feedback\", \"detect_feedback\", \"detect_feedback\", \"dialogue\", \"dialogue\", \"dialogue\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"differential_equation\", \"differential_equation\", \"differential_equation\", \"differential_equation\", \"differential_pair\", \"differential_pair\", \"differential_pair\", \"differential_pair\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"digital\", \"digital\", \"digital\", \"digital\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"directed_search\", \"directed_search\", \"directed_search\", \"directed_search\", \"directed_search\", \"distractor\", \"distractor\", \"distractor\", \"distractor\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"domain_adaptation\", \"domain_adaptation\", \"domain_adaptation\", \"double_hinge\", \"double_hinge\", \"double_hinge\", \"double_hinge\", \"dpsfrag\", \"dpsfrag\", \"dpsfrag\", \"dpsfrag\", \"dull\", \"dull\", \"dull\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"economically\", \"economically\", \"economically\", \"edginess\", \"edginess\", \"edginess\", \"edwin\", \"edwin\", \"edwin\", \"eigenfeature\", \"eigenfeature\", \"eigenfeature\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvector\", \"eigenvector\", \"eigenvector\", \"eigenvector\", \"eigenvector\", \"eigenvector\", \"embed\", \"embed\", \"embed\", \"embed\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"epoch\", \"epoch\", \"epoch\", \"equalize\", \"equalize\", \"equalize\", \"equipartion\", \"equipartion\", \"equipartion\", \"equipartition\", \"equipartition\", \"equipartition\", \"equipartition\", \"equivariant\", \"equivariant\", \"equivariant\", \"equivariant\", \"erasure\", \"erasure\", \"erasure\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"excess_risk\", \"excess_risk\", \"excess_risk\", \"excess_risk\", \"exemplar\", \"exemplar\", \"exemplar\", \"exemplar\", \"expression\", \"expression\", \"expression\", \"expression\", \"extra_structure\", \"extra_structure\", \"extra_structure\", \"extra_structure\", \"eye_velocity\", \"eye_velocity\", \"eye_velocity\", \"eye_velocity\", \"faintly\", \"faintly\", \"faintly\", \"faithful\", \"faithful\", \"faithful\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"fedback\", \"fedback\", \"fedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"fel\", \"fel\", \"fel\", \"fel\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fingerprint\", \"fingerprint\", \"fingerprint\", \"fire\", \"fire\", \"fire\", \"fire\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"fluorescent\", \"fluorescent\", \"fluorescent\", \"fogel\", \"fogel\", \"fogel\", \"fogel\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"food\", \"food\", \"food\", \"formulation\", \"formulation\", \"formulation\", \"formulation\", \"formulation\", \"formulation\", \"full_gradient\", \"full_gradient\", \"full_gradient\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"fw\", \"fw\", \"fw\", \"fw\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gealow\", \"gealow\", \"gealow\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"geometry\", \"geometry\", \"geometry\", \"geometry\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"graph_isomorphism\", \"graph_isomorphism\", \"graph_isomorphism\", \"graph_isomorphism\", \"gri\", \"gri\", \"gri\", \"ground\", \"ground\", \"ground\", \"ground\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"head_motion\", \"head_motion\", \"head_motion\", \"head_motion\", \"head_velocity\", \"head_velocity\", \"head_velocity\", \"head_velocity\", \"homology\", \"homology\", \"homology\", \"hover\", \"hover\", \"hover\", \"hurlbert\", \"hurlbert\", \"hurlbert\", \"hyperedge\", \"hyperedge\", \"hyperedge\", \"hyperedge\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraphs\", \"hypergraphs\", \"hypergraphs\", \"hypergraphs\", \"illuminant\", \"illuminant\", \"illuminant\", \"illuminate\", \"illuminate\", \"illuminate\", \"illumination\", \"illumination\", \"illumination\", \"illumination\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image_slip\", \"image_slip\", \"image_slip\", \"image_slip\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"imsecnme\", \"imsecnme\", \"imsecnme\", \"incandescent\", \"incandescent\", \"incandescent\", \"independent_component\", \"independent_component\", \"independent_component\", \"independent_component\", \"indoor\", \"indoor\", \"indoor\", \"informal\", \"informal\", \"informal\", \"informal\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"integration\", \"integration\", \"integration\", \"integration\", \"intrinsic_dimension\", \"intrinsic_dimension\", \"intrinsic_dimension\", \"intrinsic_dimension\", \"inverter\", \"inverter\", \"inverter\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"ithe\", \"ithe\", \"ithe\", \"ivariant\", \"ivariant\", \"ivariant\", \"kept\", \"kept\", \"kept\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"label\", \"label\", \"label\", \"label\", \"label\", \"labeling\", \"labeling\", \"labeling\", \"lamp\", \"lamp\", \"lamp\", \"land\", \"land\", \"land\", \"lane\", \"lane\", \"lane\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lateral_inhibition\", \"lateral_inhibition\", \"lateral_inhibition\", \"lateral_inhibition\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"lca\", \"lca\", \"lca\", \"lea\", \"lea\", \"lea\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"lift\", \"lift\", \"lift\", \"lift\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear_combination\", \"linear_combination\", \"linear_combination\", \"linear_combination\", \"linear_combination\", \"lisberger\", \"lisberger\", \"lisberger\", \"lisberger\", \"literal\", \"literal\", \"literal\", \"literal\", \"localization\", \"localization\", \"localization\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logo\", \"logo\", \"logo\", \"logo\", \"logo_traine\", \"logo_traine\", \"logo_traine\", \"logo_traine\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"lsl\", \"lsl\", \"lsl\", \"lsl\", \"mach\", \"mach\", \"mach\", \"magnification\", \"magnification\", \"magnification\", \"magnification\", \"magnification\", \"magnifying\", \"magnifying\", \"magnifying\", \"magnifying\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"map\", \"map\", \"map\", \"map\", \"map\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"marginal\", \"marginal\", \"marginal\", \"marginal\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"meta_parameter\", \"meta_parameter\", \"meta_parameter\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"micron\", \"micron\", \"micron\", \"midpoint\", \"midpoint\", \"midpoint\", \"miss\", \"miss\", \"miss\", \"miss\", \"miss\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture_density\", \"mixture_density\", \"mixture_density\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"molecular\", \"molecular\", \"molecular\", \"molecule\", \"molecule\", \"molecule\", \"mondrian\", \"mondrian\", \"mondrian\", \"monochromatic\", \"monochromatic\", \"monochromatic\", \"motor_cortex\", \"motor_cortex\", \"motor_cortex\", \"movement\", \"movement\", \"movement\", \"msl\", \"msl\", \"msl\", \"msl\", \"multi_stage\", \"multi_stage\", \"multi_stage\", \"multi_stage\", \"mws\", \"mws\", \"mws\", \"mws\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"net\", \"net\", \"net\", \"net\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object_recognition\", \"object_recognition\", \"object_recognition\", \"object_recognition\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"oculomotor\", \"oculomotor\", \"oculomotor\", \"oculomotor\", \"offset\", \"offset\", \"offset\", \"offset\", \"offset\", \"olshausen\", \"olshausen\", \"olshausen\", \"operator\", \"operator\", \"operator\", \"operator\", \"operator\", \"operator\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"ordering\", \"ordering\", \"ordering\", \"ordering\", \"ordering\", \"ordering\", \"orientation\", \"orientation\", \"orientation\", \"orientation\", \"orthogonalize\", \"orthogonalize\", \"orthogonalize\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"overconstraine\", \"overconstraine\", \"overconstraine\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack_pack\", \"pack_pack\", \"pack_pack\", \"pack_pack\", \"painter\", \"painter\", \"painter\", \"pairwise_preference\", \"pairwise_preference\", \"pairwise_preference\", \"pairwise_preference\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"partial_svd\", \"partial_svd\", \"partial_svd\", \"partial_svd\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"pcut\", \"pcut\", \"pcut\", \"pcut\", \"percentile_percentile\", \"percentile_percentile\", \"percentile_percentile\", \"percentile_percentile\", \"perception\", \"perception\", \"perception\", \"perception\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"permutahedron\", \"permutahedron\", \"permutahedron\", \"permutahedron\", \"permutahedron\", \"permutation\", \"permutation\", \"permutation\", \"permutation\", \"permutation\", \"perturbation\", \"perturbation\", \"perturbation\", \"perturbation\", \"perturbation\", \"pfms\", \"pfms\", \"pfms\", \"php\", \"php\", \"php\", \"php\", \"pitch\", \"pitch\", \"pitch\", \"place_cell\", \"place_cell\", \"place_cell\", \"place_cell\", \"place_field\", \"place_field\", \"place_field\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"poke\", \"poke\", \"poke\", \"polynomial_approximation\", \"polynomial_approximation\", \"polynomial_approximation\", \"polynomial_approximation\", \"population\", \"population\", \"population\", \"population\", \"predicate\", \"predicate\", \"predicate\", \"predicate\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"preference\", \"preference\", \"preference\", \"preference\", \"pretend\", \"pretend\", \"pretend\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"priority\", \"priority\", \"priority\", \"privacy\", \"privacy\", \"privacy\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processor\", \"processor\", \"processor\", \"processor\", \"programmable\", \"programmable\", \"programmable\", \"programmable\", \"protein\", \"protein\", \"protein\", \"protein\", \"psfrag_replacement\", \"psfrag_replacement\", \"psfrag_replacement\", \"psfrag_replacement\", \"quadrant\", \"quadrant\", \"quadrant\", \"qualification\", \"qualification\", \"qualification\", \"quantization_bit\", \"quantization_bit\", \"quantization_bit\", \"quantization_bit\", \"radar\", \"radar\", \"radar\", \"radar\", \"random\", \"random\", \"random\", \"random\", \"random\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"readjust\", \"readjust\", \"readjust\", \"receptive_field\", \"receptive_field\", \"receptive_field\", \"receptive_field\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recurrent\", \"recurrent\", \"recurrent\", \"redden\", \"redden\", \"redden\", \"reddish\", \"reddish\", \"reddish\", \"regret\", \"regret\", \"regret\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"regularized_permutahedron\", \"regularized_permutahedron\", \"regularized_permutahedron\", \"regularized_permutahedron\", \"reject_option\", \"reject_option\", \"reject_option\", \"reject_option\", \"rejection\", \"rejection\", \"rejection\", \"rejection\", \"relational_theory\", \"relational_theory\", \"relational_theory\", \"relational_theory\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"replicate\", \"replicate\", \"replicate\", \"replicate\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"resistive\", \"resistive\", \"resistive\", \"resistive_grid\", \"resistive_grid\", \"resistive_grid\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"ridge\", \"ridge\", \"ridge\", \"rigid\", \"rigid\", \"rigid\", \"rigid\", \"ritter\", \"ritter\", \"ritter\", \"rotate\", \"rotate\", \"rotate\", \"rotated_neuron\", \"rotated_neuron\", \"rotated_neuron\", \"row\", \"row\", \"row\", \"row\", \"row\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"rqps\", \"rqps\", \"rqps\", \"rqps\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sand\", \"sand\", \"sand\", \"sand\", \"sbp\", \"sbp\", \"sbp\", \"sbp\", \"scene\", \"scene\", \"scene\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"secondary\", \"secondary\", \"secondary\", \"secondary\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"selective_sampling\", \"selective_sampling\", \"selective_sampling\", \"selective_sampling\", \"selective_sampling\", \"self_organize\", \"self_organize\", \"self_organize\", \"selforganize\", \"selforganize\", \"selforganize\", \"selforganizing\", \"selforganizing\", \"selforganizing\", \"sensory\", \"sensory\", \"sensory\", \"sensory\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"seriation_problem\", \"seriation_problem\", \"seriation_problem\", \"seriation_problem\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"sgn\", \"sgn\", \"sgn\", \"sharply_peake\", \"sharply_peake\", \"sharply_peake\", \"sharply_peake\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"skin\", \"skin\", \"skin\", \"sky\", \"sky\", \"sky\", \"snake\", \"snake\", \"snake\", \"snapshot\", \"snapshot\", \"snapshot\", \"snapshot\", \"sofm\", \"sofm\", \"sofm\", \"sofmfor\", \"sofmfor\", \"sofmfor\", \"solidly\", \"solidly\", \"solidly\", \"solubility\", \"solubility\", \"solubility\", \"som\", \"som\", \"som\", \"som\", \"som\", \"sorting_network\", \"sorting_network\", \"sorting_network\", \"sorting_network\", \"sorting_network\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source_separation\", \"source_separation\", \"source_separation\", \"source_separation\", \"spectacle\", \"spectacle\", \"spectacle\", \"spectacle\", \"spike\", \"spike\", \"spike\", \"spike\", \"square_lattice\", \"square_lattice\", \"square_lattice\", \"square_lattice\", \"squash\", \"squash\", \"squash\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"state\", \"state\", \"state\", \"state\", \"state\", \"steady_state\", \"steady_state\", \"steady_state\", \"steadystate\", \"steadystate\", \"steadystate\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stress\", \"stress\", \"stress\", \"stress\", \"subexpression\", \"subexpression\", \"subexpression\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subtract\", \"subtract\", \"subtract\", \"suffix\", \"suffix\", \"suffix\", \"sunlight\", \"sunlight\", \"sunlight\", \"surround\", \"surround\", \"surround\", \"surround\", \"svd\", \"svd\", \"svd\", \"svd\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbolic\", \"symbolic\", \"symbolic\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry_breaking\", \"symmetry_breaking\", \"symmetry_breaking\", \"symmetry_breaking\", \"synaptic\", \"synaptic\", \"synaptic\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tactical\", \"tactical\", \"tactical\", \"tandem\", \"tandem\", \"tandem\", \"target\", \"target\", \"target\", \"target\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"teach\", \"teach\", \"teach\", \"template\", \"template\", \"template\", \"template\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term_equivalent\", \"term_equivalent\", \"term_equivalent\", \"term_equivalent\", \"tessellation\", \"tessellation\", \"tessellation\", \"textbook\", \"textbook\", \"textbook\", \"textbook\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"tic\", \"tic\", \"tic\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tinge\", \"tinge\", \"tinge\", \"toot\", \"toot\", \"toot\", \"top_pca\", \"top_pca\", \"top_pca\", \"topic\", \"topic\", \"topic\", \"topic\", \"total_variation\", \"total_variation\", \"total_variation\", \"total_variation\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"trainer\", \"trainer\", \"trainer\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"transistor\", \"transistor\", \"transistor\", \"transistor\", \"triad\", \"triad\", \"triad\", \"triad\", \"truncate\", \"truncate\", \"truncate\", \"truncate\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unmixe\", \"unmixe\", \"unmixe\", \"unmodified_pathway\", \"unmodified_pathway\", \"unmodified_pathway\", \"unmodified_pathway\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"utsugi\", \"utsugi\", \"utsugi\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variational\", \"variational\", \"variational\", \"variational\", \"variational\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"verification\", \"verification\", \"verification\", \"vestibulo_ocular\", \"vestibulo_ocular\", \"vestibulo_ocular\", \"vestibulo_ocular\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"viewpoint\", \"viewpoint\", \"viewpoint\", \"viewpoint\", \"visible_unit\", \"visible_unit\", \"visible_unit\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"vlmms\", \"vlmms\", \"vlmms\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voronoi\", \"voronoi\", \"voronoi\", \"warping\", \"warping\", \"warping\", \"warping\", \"warping_function\", \"warping_function\", \"warping_function\", \"warping_function\", \"wavefront\", \"wavefront\", \"wavefront\", \"weakness\", \"weakness\", \"weakness\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"win\", \"win\", \"win\", \"worm\", \"worm\", \"worm\"]}, \"mdsDat\": {\"y\": [-0.03407610023250715, 0.0557209142900437, 0.05401006728948615, -0.04722762256073433, -0.043904887011460635, 0.00893337520363761, 0.008277757167664239, -0.0017335041461296536], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [58.89595031738281, 17.232505798339844, 12.918424606323242, 6.068926811218262, 3.192707061767578, 1.2412291765213013, 0.44964906573295593, 0.0005995376850478351], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"x\": [-0.16880826833072057, -0.07602669197511511, -0.053432063802383, -0.0225211381332057, 0.02305974676829492, 0.07089000632584053, 0.10773594916827045, 0.11910245997901842]}, \"R\": 30, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Term\": [\"network\", \"datum\", \"set\", \"model\", \"error\", \"matrix\", \"use\", \"object\", \"cluster\", \"system\", \"number\", \"term\", \"figure\", \"input\", \"neuron\", \"current\", \"weight\", \"state\", \"training\", \"visual\", \"formulation\", \"image\", \"time\", \"give\", \"neural\", \"view\", \"convex\", \"theory\", \"show\", \"vector\", \"topic\", \"decision_maker\", \"cost\", \"label\", \"variational\", \"sample\", \"iteration\", \"objective\", \"privacy\", \"regret\", \"confusion\", \"margin\", \"labeling\", \"pitch\", \"classification\", \"manifold\", \"empirical\", \"anomaly\", \"domain_adaptation\", \"loss\", \"class\", \"convergence_rate\", \"oracle\", \"full_gradient\", \"logistic_regression\", \"guarantee\", \"truncate\", \"unlabeled\", \"crf\", \"exemplar\", \"optimization\", \"convergence\", \"epoch\", \"dataset\", \"miss\", \"marginal\", \"distribution\", \"gaussian\", \"stochastic\", \"gradient\", \"source\", \"method\", \"algorithm\", \"metric\", \"datum\", \"set\", \"let\", \"random\", \"point\", \"problem\", \"section\", \"feature\", \"obtain\", \"example\", \"case\", \"use\", \"function\", \"matrix\", \"task\", \"learn\", \"error\", \"give\", \"model\", \"approach\", \"show\", \"result\", \"base\", \"follow\", \"also\", \"value\", \"time\", \"figure\", \"training\", \"number\", \"fingerprint\", \"circular_fingerprint\", \"symbolic\", \"binaryconnect\", \"molecule\", \"motor_cortex\", \"agent\", \"mixture_density\", \"chip\", \"rotated_neuron\", \"trainer\", \"brnn\", \"feedback\", \"homology\", \"land\", \"solubility\", \"lane\", \"recurrent\", \"molecular\", \"bond\", \"vlmms\", \"detect_feedback\", \"radar\", \"subtract\", \"subexpression\", \"conserve\", \"visible_unit\", \"teach\", \"pfms\", \"suffix\", \"protein\", \"rotate\", \"atom\", \"symbol\", \"layer\", \"network\", \"template\", \"rule\", \"memory\", \"architecture\", \"weight\", \"movement\", \"block\", \"neural\", \"system\", \"output\", \"color\", \"train\", \"sequence\", \"unit\", \"expression\", \"state\", \"neuron\", \"training\", \"input\", \"change\", \"use\", \"learn\", \"model\", \"prediction\", \"action\", \"goal\", \"noise\", \"time\", \"signal\", \"vector\", \"figure\", \"result\", \"learning\", \"value\", \"problem\", \"function\", \"performance\", \"set\", \"show\", \"base\", \"number\", \"datum\", \"dialogue\", \"place_cell\", \"meta_parameter\", \"stimulus\", \"sensory\", \"auditory\", \"place_field\", \"snapshot\", \"spike\", \"worm\", \"toot\", \"priority\", \"bdmm\", \"animal\", \"asymmetry\", \"city\", \"food\", \"snake\", \"dendritic\", \"attention\", \"differential_equation\", \"stress\", \"visual\", \"brain\", \"top_pca\", \"poke\", \"receptive_field\", \"eigenfeature\", \"fire\", \"localization\", \"synaptic\", \"orientation\", \"cortical\", \"body\", \"neuron\", \"firing_rate\", \"perception\", \"integration\", \"response\", \"population\", \"location\", \"prior\", \"system\", \"input\", \"bias\", \"model\", \"state\", \"network\", \"map\", \"time\", \"neural\", \"figure\", \"likelihood\", \"function\", \"constraint\", \"different\", \"value\", \"show\", \"use\", \"result\", \"feature\", \"number\", \"learn\", \"give\", \"estimate\", \"datum\", \"symmetry\", \"committee\", \"hyperedge\", \"hypergraph\", \"term_equivalent\", \"multi_stage\", \"predicate\", \"clique_expansion\", \"literal\", \"symmetry_breaking\", \"capped_regularization\", \"relational_theory\", \"hypergraphs\", \"convex_relaxation\", \"lasso\", \"lateral_inhibition\", \"pcut\", \"secondary\", \"replicate\", \"excess_risk\", \"php\", \"density_estimator\", \"bootc\", \"sbp\", \"lift\", \"square_lattice\", \"fw\", \"graph_isomorphism\", \"mws\", \"diffusion\", \"cut\", \"ground\", \"distractor\", \"total_variation\", \"break\", \"partition\", \"delay\", \"term\", \"evidence\", \"theory\", \"error\", \"target\", \"cluster\", \"generalization\", \"stage\", \"network\", \"weight\", \"set\", \"bind\", \"find\", \"performance\", \"regularization\", \"model\", \"time\", \"kernel\", \"number\", \"define\", \"show\", \"give\", \"function\", \"use\", \"base\", \"let\", \"order\", \"result\", \"problem\", \"rpca\", \"warping_function\", \"pack_pack\", \"intrinsic_dimension\", \"pack\", \"bwgp\", \"coherence_parameter\", \"polynomial_approximation\", \"informal\", \"pairwise_preference\", \"msl\", \"creep\", \"psfrag_replacement\", \"cdn\", \"lsl\", \"compressive\", \"fel\", \"logo_traine\", \"quantization_bit\", \"logo\", \"percentile_percentile\", \"textbook\", \"triad\", \"coherence\", \"partial_svd\", \"preference\", \"extra_structure\", \"aileron\", \"warping\", \"dpsfrag\", \"child\", \"svd\", \"eigenvector\", \"recovery\", \"geometry\", \"rank\", \"perturbation\", \"ordering\", \"instruction\", \"recover\", \"row\", \"embedding\", \"dimension\", \"coherent\", \"datum\", \"matrix\", \"embed\", \"cluster\", \"number\", \"set\", \"subspace\", \"model\", \"use\", \"view\", \"observation\", \"figure\", \"approximate\", \"give\", \"analysis\", \"eigenvalue\", \"method\", \"problem\", \"permutahedron\", \"sorting_network\", \"birkhoff_polytope\", \"selective_sampling\", \"head_velocity\", \"double_hinge\", \"reject_option\", \"rejection\", \"comparator\", \"directed_search\", \"unmodified_pathway\", \"spectacle\", \"head_motion\", \"image_slip\", \"rigid\", \"rqps\", \"seriation_problem\", \"eye_velocity\", \"birkhoff\", \"viewpoint\", \"linear_combination\", \"sand\", \"convex_hull\", \"regularized_permutahedron\", \"pathway\", \"vestibulo_ocular\", \"magnifying\", \"oculomotor\", \"lisberger\", \"fogel\", \"chow\", \"differential_pair\", \"permutation\", \"gain\", \"object\", \"view\", \"formulation\", \"operator\", \"circuit\", \"object_recognition\", \"scheme\", \"current\", \"adaptation\", \"concept\", \"relaxation\", \"voltage\", \"system\", \"implement\", \"constraint\", \"model\", \"image\", \"figure\", \"network\", \"vector\", \"use\", \"linear\", \"represent\", \"equipartition\", \"som\", \"source_separation\", \"sharply_peake\", \"equivariant\", \"voronoi\", \"win\", \"programmable\", \"branch\", \"independent_component\", \"conveyor\", \"apap\", \"digital\", \"equalize\", \"verification\", \"faithful\", \"cancellation\", \"sgn\", \"self_organize\", \"sofm\", \"anisotropic\", \"lea\", \"branched\", \"unmixe\", \"blind_separation\", \"wavefront\", \"gealow\", \"erasure\", \"magnification\", \"steady_state\", \"processor\", \"cell\", \"quadrant\", \"contour\", \"chip\", \"offset\", \"align\", \"current\", \"axis\", \"transistor\", \"density\", \"unit\", \"voltage\", \"mixture\", \"fig\", \"source\", \"nature\", \"partition\", \"dynamic\", \"processing\", \"layer\", \"net\", \"parallel\", \"bauer\", \"selforganize\", \"lca\", \"tessellation\", \"overconstraine\", \"equipartion\", \"steadystate\", \"componentwise\", \"selforganizing\", \"ridge\", \"ritter\", \"tandem\", \"olshausen\", \"orthogonalize\", \"hover\", \"utsugi\", \"bend\", \"ivariant\", \"ithe\", \"gri\", \"sofmfor\", \"bifurcation\", \"midpoint\", \"inverter\", \"fedback\", \"concurrently\", \"imsecnme\", \"pretend\", \"kept\", \"coincidence\", \"tic\", \"color\", \"land\", \"surround\", \"camera\", \"mach\", \"lamp\", \"edginess\", \"qualification\", \"solidly\", \"bluer\", \"awash\", \"readjust\", \"fluorescent\", \"illumination\", \"faintly\", \"illuminant\", \"dull\", \"squash\", \"micron\", \"cal\", \"tactical\", \"edwin\", \"redden\", \"accident\", \"economically\", \"reddish\", \"mondrian\", \"illuminate\", \"hurlbert\", \"painter\", \"skin\", \"sunlight\", \"color_constancy\", \"incandescent\", \"resistive_grid\", \"tinge\", \"network\", \"image\", \"set\", \"sky\", \"card\", \"resistive\", \"abundance\", \"use\", \"weakness\", \"california_institute\", \"constancy\", \"monochromatic\", \"darkness\", \"scene\", \"subtract\", \"blur\", \"indoor\", \"model\", \"training\", \"bright\", \"function\", \"time\", \"point\", \"number\", \"base\", \"give\", \"problem\", \"value\", \"performance\", \"error\", \"learn\", \"show\", \"feature\", \"task\", \"system\", \"datum\", \"different\", \"see\", \"result\", \"figure\", \"sample\", \"method\"], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4973999857902527, 0.4936999976634979, 0.4860000014305115, 0.4844000041484833, 0.4810999929904938, 0.4796000123023987, 0.4765999913215637, 0.4706000089645386, 0.4699000120162964, 0.4675999879837036, 0.4643000066280365, 0.4586000144481659, 0.4577000141143799, 0.45669999718666077, 0.45590001344680786, 0.4555000066757202, 0.45509999990463257, 0.45500001311302185, 0.45399999618530273, 0.45179998874664307, 0.45179998874664307, 0.4499000012874603, 0.44909998774528503, 0.4449000060558319, 0.44449999928474426, 0.44449999928474426, 0.44429999589920044, 0.44119998812675476, 0.4399999976158142, 0.4399000108242035, 0.4343000054359436, 0.43959999084472656, 0.4397999942302704, 0.4307999908924103, 0.4383000135421753, 0.43470001220703125, 0.4106000065803528, 0.41920000314712524, 0.4196000099182129, 0.4081000089645386, 0.4198000133037567, 0.3643999993801117, 0.38339999318122864, 0.42010000348091125, 0.3138999938964844, 0.3061000108718872, 0.37700000405311584, 0.3763999938964844, 0.321399986743927, 0.30059999227523804, 0.3522999882698059, 0.301800012588501, 0.34439998865127563, 0.30390000343322754, 0.3172999918460846, 0.18790000677108765, 0.22579999268054962, 0.32519999146461487, 0.2757999897003174, 0.17090000212192535, 0.22699999809265137, 0.22519999742507935, 0.07010000199079514, 0.27639999985694885, 0.1777999997138977, 0.1712000072002411, 0.19529999792575836, 0.2727000117301941, 0.22290000319480896, 0.1378999948501587, 0.04800000041723251, 0.0729999989271164, 0.05689999833703041, 0.08489999920129776, 1.705299973487854, 1.6644999980926514, 1.649999976158142, 1.6420999765396118, 1.635200023651123, 1.6332999467849731, 1.6174999475479126, 1.5927000045776367, 1.5896999835968018, 1.5858999490737915, 1.5853999853134155, 1.5758999586105347, 1.5751999616622925, 1.555400013923645, 1.5550999641418457, 1.554800033569336, 1.5420000553131104, 1.5357999801635742, 1.5298000574111938, 1.5271999835968018, 1.523900032043457, 1.5234999656677246, 1.5152000188827515, 1.5121999979019165, 1.5110000371932983, 1.5104000568389893, 1.5085999965667725, 1.4962999820709229, 1.4962999820709229, 1.4960999488830566, 1.492900013923645, 1.48580002784729, 1.4694000482559204, 1.469499945640564, 1.3213000297546387, 1.1519999504089355, 1.3983999490737915, 1.2314000129699707, 1.2757999897003174, 1.3107000589370728, 1.0921000242233276, 1.2956000566482544, 1.2970999479293823, 0.9280999898910522, 0.8896999955177307, 0.913100004196167, 1.22160005569458, 0.8693000078201294, 0.9839000105857849, 1.0011999607086182, 1.1651999950408936, 0.7261000275611877, 0.861299991607666, 0.6116999983787537, 0.6815000176429749, 0.9598000049591064, -0.006500000134110451, 0.1437000036239624, -0.03700000047683716, 0.7955999970436096, 0.9078999757766724, 0.7932999730110168, 0.5753999948501587, 0.032099999487400055, 0.7092999815940857, 0.25110000371932983, 0.03099999949336052, -0.12309999763965607, 0.3124000132083893, -0.04479999840259552, -0.35749998688697815, -0.4325999915599823, 0.07329999655485153, -0.7174000144004822, -0.289900004863739, -0.18240000307559967, -0.11320000141859055, -0.756600022315979, 1.9990999698638916, 1.9565000534057617, 1.9383000135421753, 1.9297000169754028, 1.913599967956543, 1.9114999771118164, 1.8954999446868896, 1.892799973487854, 1.889799952507019, 1.8700000047683716, 1.857800006866455, 1.857800006866455, 1.8557000160217285, 1.8489999771118164, 1.844099998474121, 1.8336000442504883, 1.8250000476837158, 1.822100043296814, 1.8108999729156494, 1.8087999820709229, 1.8034000396728516, 1.801900029182434, 1.7999000549316406, 1.7972999811172485, 1.795699954032898, 1.795199990272522, 1.7940000295639038, 1.7896000146865845, 1.789199948310852, 1.781599998474121, 1.770900011062622, 1.6928999423980713, 1.7178000211715698, 1.7568999528884888, 1.3911000490188599, 1.6509000062942505, 1.688599944114685, 1.6979000568389893, 1.3551000356674194, 1.4265999794006348, 1.2493000030517578, 1.0286999940872192, 0.7200999855995178, 0.6791999936103821, 1.3777999877929688, 0.10930000245571136, 0.5081999897956848, 0.0625, 0.8116999864578247, 0.08540000021457672, 0.3301999866962433, 0.04149999842047691, 0.9642000198364258, -0.2345999926328659, 0.6538000106811523, 0.13249999284744263, -0.04879999905824661, -0.20090000331401825, -0.6402000188827515, -0.25920000672340393, -0.38280001282691956, -0.23479999601840973, -0.6743999719619751, -0.3458000123500824, 0.04479999840259552, -0.9478999972343445, 2.682800054550171, 2.6561999320983887, 2.5985000133514404, 2.597599983215332, 2.5697999000549316, 2.5601000785827637, 2.546099901199341, 2.506999969482422, 2.496999979019165, 2.4960999488830566, 2.4821999073028564, 2.4798998832702637, 2.4746999740600586, 2.474400043487549, 2.473099946975708, 2.463200092315674, 2.4507999420166016, 2.4419000148773193, 2.424799919128418, 2.4147000312805176, 2.4142000675201416, 2.4045000076293945, 2.3970000743865967, 2.3852999210357666, 2.3821001052856445, 2.3780999183654785, 2.3671000003814697, 2.352299928665161, 2.352099895477295, 2.351599931716919, 2.330899953842163, 2.282599925994873, 2.2353999614715576, 2.2664999961853027, 2.1359000205993652, 1.770300030708313, 2.0875000953674316, 1.2389999628067017, 1.6562000513076782, 1.1901999711990356, 0.6611999869346619, 1.1478999853134155, 0.9007999897003174, 1.3859000205993652, 1.628600001335144, 0.11299999803304672, 0.6136000156402588, -0.18469999730587006, 0.9031999707221985, 0.5497999787330627, 0.19979999959468842, 0.9229000210762024, -0.5619000196456909, -0.08699999749660492, 0.6446999907493591, -0.025599999353289604, 0.3077000081539154, -0.2353000044822693, -0.1535000056028366, -0.4474000036716461, -0.7210999727249146, -0.20659999549388885, 0.3612000048160553, 0.14820000529289246, -0.4912000000476837, -0.6723999977111816, 3.224299907684326, 3.1387999057769775, 3.077500104904175, 3.0724000930786133, 3.0594000816345215, 3.0185999870300293, 3.011199951171875, 2.9863998889923096, 2.915800094604492, 2.9028000831604004, 2.890000104904175, 2.8864998817443848, 2.8833999633789062, 2.873800039291382, 2.8636999130249023, 2.8610999584198, 2.8608999252319336, 2.83870005607605, 2.837899923324585, 2.8333001136779785, 2.819999933242798, 2.793299913406372, 2.7927000522613525, 2.773699998855591, 2.7695000171661377, 2.757699966430664, 2.7135000228881836, 2.70989990234375, 2.70740008354187, 2.7047998905181885, 2.624799966812134, 2.68179988861084, 2.589400053024292, 2.5048000812530518, 2.553999900817871, 2.184799909591675, 2.1686999797821045, 2.58489990234375, 2.528599977493286, 2.017199993133545, 1.7700999975204468, 1.9556000232696533, 1.4565999507904053, 2.2397000789642334, 0.18960000574588776, 0.7152000069618225, 1.4200999736785889, 0.7682999968528748, 0.23980000615119934, -0.2858000099658966, 1.6991000175476074, -0.47760000824928284, -0.6147000193595886, 1.1883000135421753, 0.8956999778747559, -0.2565999925136566, 0.6351000070571899, -0.5138999819755554, 0.24469999969005585, 1.2781000137329102, -1.045300006866455, -1.1541999578475952, 3.8722000122070312, 3.8341000080108643, 3.697499990463257, 3.569700002670288, 3.5151000022888184, 3.472100019454956, 3.355299949645996, 3.3508999347686768, 3.346400022506714, 3.3148000240325928, 3.2604000568389893, 3.2602999210357666, 3.2595999240875244, 3.2590999603271484, 3.234600067138672, 3.2000999450683594, 3.1923999786376953, 3.166599988937378, 3.110100030899048, 3.107300043106079, 3.0797998905181885, 3.045799970626831, 3.0274999141693115, 2.99429988861084, 2.917099952697754, 2.914900064468384, 2.9140000343322754, 2.913800001144409, 2.913100004196167, 2.8575000762939453, 2.8526999950408936, 2.844099998474121, 2.710599899291992, 2.426800012588501, 2.0994999408721924, 2.150899887084961, 2.1303000450134277, 2.347399950027466, 2.309499979019165, 2.417099952697754, 1.704699993133545, 1.09089994430542, 1.805799961090088, 1.705299973487854, 1.5698000192642212, 1.794700026512146, -0.02370000071823597, 1.2208000421524048, 0.3799000084400177, -1.2563999891281128, -0.39489999413490295, -0.6421999931335449, -0.9836999773979187, -0.37229999899864197, -1.4220000505447388, -0.053599998354911804, 0.06719999760389328, 4.2617998123168945, 3.8857998847961426, 3.6505000591278076, 3.5576999187469482, 3.441800117492676, 3.3215999603271484, 3.3134000301361084, 3.25, 3.191499948501587, 3.1900999546051025, 3.140700101852417, 3.13919997215271, 3.0717999935150146, 2.9605000019073486, 2.9570000171661377, 2.9565999507904053, 2.9300999641418457, 2.874000072479248, 2.757200002670288, 2.695499897003174, 2.694000005722046, 2.6928999423980713, 2.6923000812530518, 2.688699960708618, 2.663300037384033, 2.650399923324585, 2.649199962615967, 2.6486001014709473, 2.643899917602539, 2.6270999908447266, 2.607800006866455, 2.4463999271392822, 2.5541000366210938, 2.3842999935150146, 2.1500000953674316, 2.2632999420166016, 2.3064000606536865, 1.4567999839782715, 2.267699956893921, 2.2202000617980957, 1.069599986076355, 0.5361999869346619, 1.361199975013733, 0.7208999991416931, 0.4399000108242035, 0.257999986410141, 1.2267999649047852, 0.3003999888896942, 0.4797999858856201, 0.5145999789237976, -0.02250000089406967, 1.1230000257492065, 1.0189000368118286, 1.705299973487854, 1.705299973487854, 1.7051000595092773, 1.7050000429153442, 1.7050000429153442, 1.7050000429153442, 1.7049000263214111, 1.7049000263214111, 1.704800009727478, 1.704699993133545, 1.704699993133545, 1.704699993133545, 1.704699993133545, 1.704699993133545, 1.7045999765396118, 1.7045999765396118, 1.7045999765396118, 1.7044999599456787, 1.7044999599456787, 1.704300045967102, 1.704200029373169, 1.7041000127792358, 1.7038999795913696, 1.6949000358581543, 1.6949000358581543, 1.694599986076355, 1.694599986076355, 1.6944999694824219, 1.6944999694824219, 1.6944999694824219, 1.6943999528884888, -0.4244999885559082, 0.35010001063346863, 0.04179999977350235, 0.25679999589920044, 1.1187000274658203, 1.5713000297546387, 1.2056000232696533, 1.5709999799728394, 1.5706000328063965, 1.5705000162124634, 1.5703999996185303, 1.570199966430664, 1.201200008392334, 0.7064999938011169, 1.5699000358581543, 0.8682000041007996, 1.5698000192642212, 1.5694999694824219, 1.5693999528884888, 1.5693000555038452, 1.569100022315979, 1.569200038909912, 1.569200038909912, 1.5688999891281128, 1.5687999725341797, 1.5687999725341797, 1.0121999979019165, 1.3025000095367432, 1.56850004196167, 1.5684000253677368, 1.0946999788284302, 1.4226000308990479, 0.7200999855995178, 1.1856000423431396, 1.0830999612808228, 1.4204000234603882, -3.0694000720977783, -2.5244998931884766, -3.400899887084961, 0.6470000147819519, 1.0780999660491943, 1.1779999732971191, 1.4193999767303467, -3.4834001064300537, 0.6456000208854675, 1.0680999755859375, 1.1172000169754028, 1.4192999601364136, 1.4185999631881714, -0.4652000069618225, 0.3012999892234802, 1.0484999418258667, 1.0478999614715576, -3.6298000812530518, -2.93969988822937, 0.8026999831199646, -3.302500009536743, -3.02620005607605, -3.0148000717163086, -2.892199993133545, -3.0153000354766846, -2.996799945831299, -3.3487000465393066, -2.984999895095825, -2.7736001014709473, -3.0157999992370605, -3.4003000259399414, -3.1905999183654785, -3.1673998832702637, -2.874300003051758, -2.664900064468384, -3.5601000785827637, -2.7973999977111816, -2.528899908065796, -3.269200086593628, -3.0903000831604004, -3.2012999057769775, -3.4086999893188477], \"Freq\": [859.0, 1055.0, 1229.0, 1387.0, 609.0, 390.0, 1311.0, 164.0, 320.0, 409.0, 560.0, 292.0, 609.0, 409.0, 266.0, 122.0, 328.0, 456.0, 612.0, 185.0, 101.0, 456.0, 667.0, 614.0, 380.0, 106.0, 198.0, 212.0, 731.0, 422.0, 83.08454895019531, 69.65830993652344, 211.44993591308594, 237.1146240234375, 107.70500183105469, 649.4419555664062, 209.63577270507812, 186.62718200683594, 40.626068115234375, 41.38180160522461, 36.73210906982422, 45.682945251464844, 33.719337463378906, 43.140235900878906, 286.99334716796875, 56.750118255615234, 118.5116195678711, 31.904800415039062, 31.852903366088867, 178.79415893554688, 391.1869812011719, 40.06355285644531, 30.72637176513672, 28.010055541992188, 33.904266357421875, 81.04573822021484, 32.132877349853516, 30.29283905029297, 26.075815200805664, 46.760986328125, 365.8337707519531, 119.31088256835938, 78.28690338134766, 177.6161346435547, 72.62644958496094, 91.36370849609375, 513.6162109375, 197.04718017578125, 170.416259765625, 200.25302124023438, 129.36959838867188, 712.7069091796875, 381.8750915527344, 114.10474395751953, 851.1100463867188, 983.1771850585938, 250.86392211914062, 242.40069580078125, 524.7442626953125, 715.6364135742188, 322.5211181640625, 562.2256469726562, 293.9385070800781, 395.2441711425781, 349.2679748535156, 931.9321899414062, 673.5101928710938, 318.5594482421875, 398.64410400390625, 640.9010620117188, 450.70635986328125, 453.02899169921875, 876.3762817382812, 362.6944580078125, 514.7388916015625, 515.0308837890625, 457.27154541015625, 354.9696044921875, 375.2217102050781, 403.7975769042969, 412.2047119140625, 386.15191650390625, 381.63238525390625, 359.3775939941406, 50.28955078125, 27.025033950805664, 23.790145874023438, 21.587358474731445, 20.06686782836914, 20.734037399291992, 68.55461120605469, 16.6628360748291, 25.425128936767578, 13.868572235107422, 13.818765640258789, 15.098109245300293, 85.75054931640625, 11.516958236694336, 16.439382553100586, 11.54004955291748, 10.739620208740234, 28.50418472290039, 13.873838424682617, 9.990964889526367, 10.573466300964355, 9.957706451416016, 12.294312477111816, 13.277033805847168, 9.222274780273438, 9.193333625793457, 9.205342292785645, 8.989324569702148, 9.086098670959473, 12.820775985717773, 39.470088958740234, 13.834600448608398, 18.508378982543945, 17.488414764404297, 88.46806335449219, 468.6121826171875, 32.43943405151367, 113.1822509765625, 66.04418182373047, 47.421287536621094, 168.70388793945312, 45.6870002746582, 44.6078987121582, 165.7781524658203, 171.91677856445312, 138.79351806640625, 44.19057083129883, 139.9159698486328, 91.21586608886719, 83.62255096435547, 49.22771072387695, 162.44415283203125, 108.5311279296875, 194.47340393066406, 139.51858520507812, 75.67301940917969, 224.4811248779297, 182.47987365722656, 230.3809356689453, 73.68817138671875, 63.39466857910156, 69.72785949707031, 79.2721939086914, 118.7100830078125, 69.07112884521484, 93.64691925048828, 108.33426666259766, 112.27470397949219, 83.88285827636719, 98.41116333007812, 108.43724822998047, 102.01422882080078, 87.71758270263672, 103.36701202392578, 94.34219360351562, 91.70475006103516, 86.25685119628906, 85.36870574951172, 58.1758918762207, 29.29008674621582, 23.626142501831055, 50.26954650878906, 37.27041244506836, 19.224260330200195, 16.422346115112305, 22.179462432861328, 91.42357635498047, 14.232125282287598, 12.855382919311523, 12.846661567687988, 12.838298797607422, 32.2823371887207, 12.912613868713379, 16.9090576171875, 10.697879791259766, 10.683771133422852, 9.97719955444336, 45.175743103027344, 12.884995460510254, 27.216264724731445, 145.1758575439453, 53.58034133911133, 12.828483581542969, 9.262603759765625, 10.572278022766113, 12.769068717956543, 23.85262680053711, 11.384598731994629, 41.50314712524414, 42.51483917236328, 25.9996395111084, 16.33755874633789, 138.20582580566406, 29.29401206970215, 22.680429458618164, 20.95060920715332, 54.19734573364258, 41.92314529418945, 44.469852447509766, 64.65240478515625, 108.782470703125, 104.3538589477539, 31.621540069580078, 199.91360473632812, 97.94033813476562, 118.1624755859375, 53.57576370239258, 93.85784912109375, 68.34746551513672, 82.0670394897461, 42.328147888183594, 93.22000122070312, 50.87882614135742, 67.81640625, 73.48054504394531, 77.30967712402344, 89.29997253417969, 73.45629119873047, 62.188262939453125, 57.25703811645508, 60.365108489990234, 56.13981246948242, 50.08921813964844, 52.85580825805664, 43.41361999511719, 27.39905548095703, 13.066471099853516, 13.060391426086426, 11.058746337890625, 10.996952056884766, 12.588330268859863, 8.514443397521973, 8.031885147094727, 8.028897285461426, 7.955892562866211, 7.527784824371338, 7.50662088394165, 14.8665771484375, 11.493468284606934, 8.973796844482422, 9.42161750793457, 12.827669143676758, 8.416955947875977, 6.41157341003418, 6.012640953063965, 5.975106239318848, 5.945772171020508, 5.505677223205566, 11.068426132202148, 5.448460578918457, 5.817874431610107, 5.002315044403076, 5.001163482666016, 19.91739845275879, 29.427915573120117, 10.554594993591309, 10.826448440551758, 8.804804801940918, 13.971224784851074, 42.93208694458008, 13.096826553344727, 61.32244110107422, 26.065715789794922, 42.437721252441406, 71.70040130615234, 39.31663131713867, 47.93329620361328, 27.306074142456055, 16.958860397338867, 58.387611389160156, 36.820716857910156, 62.018043518066406, 27.058595657348633, 32.15312194824219, 35.0587158203125, 23.10694122314453, 48.00183868408203, 37.111385345458984, 26.236648559570312, 33.15787124633789, 28.90752410888672, 35.089576721191406, 31.965173721313477, 35.40011978149414, 38.690677642822266, 31.52366828918457, 25.44438362121582, 26.205354690551758, 27.363862991333008, 27.871267318725586, 17.710376739501953, 10.114640235900879, 7.066496849060059, 10.414093017578125, 6.703566551208496, 6.574178218841553, 5.6552653312683105, 5.292758941650391, 4.535411357879639, 4.512479305267334, 7.298263072967529, 4.477051734924316, 5.589818000793457, 4.168868541717529, 5.814138889312744, 6.633360385894775, 3.8627665042877197, 3.8086490631103516, 4.089385509490967, 3.7966184616088867, 3.5111708641052246, 3.4509565830230713, 3.4497570991516113, 5.295454502105713, 3.15348482131958, 9.957167625427246, 2.803605079650879, 3.0521607398986816, 3.049224376678467, 2.790224552154541, 17.74337387084961, 4.186362266540527, 12.1038236618042, 11.871234893798828, 7.231324672698975, 20.759384155273438, 17.87993621826172, 5.155097007751465, 5.559902191162109, 11.44711685180664, 15.42597770690918, 11.18433952331543, 17.83490753173828, 7.063241004943848, 40.74330139160156, 25.50578498840332, 14.052408218383789, 22.087169647216797, 22.745332717895508, 29.486576080322266, 9.472503662109375, 27.471878051757812, 22.639698028564453, 11.155011177062988, 11.926898002624512, 15.054150581359863, 10.192767143249512, 11.727601051330566, 9.785496711730957, 8.270537376403809, 9.435578346252441, 9.056852340698242, 5.438535213470459, 4.875000953674316, 3.544450283050537, 3.213428497314453, 2.271296501159668, 4.015725612640381, 2.559793472290039, 2.695366144180298, 1.843329668045044, 2.0779545307159424, 1.5061713457107544, 1.5060150623321533, 1.5057651996612549, 1.5053585767745972, 2.8022561073303223, 1.4663587808609009, 1.4609662294387817, 1.3141865730285645, 1.2803875207901, 1.8618662357330322, 3.024015426635742, 1.352980375289917, 1.6176058053970337, 1.0898454189300537, 3.200340509414673, 0.9314337968826294, 0.9310329556465149, 0.9309276938438416, 0.930475652217865, 0.9039850831031799, 1.1251105070114136, 1.291500210762024, 8.366144180297852, 6.292318344116211, 16.66771697998047, 11.356256484985352, 10.58459758758545, 4.398565292358398, 2.8215889930725098, 2.306556463241577, 3.810957193374634, 4.5261616706848145, 3.002357244491577, 2.997514247894287, 3.032947540283203, 2.730231285095215, 4.967715740203857, 2.9034674167633057, 3.7173445224761963, 4.901889324188232, 3.8150224685668945, 3.9800751209259033, 3.988152027130127, 3.616281509399414, 3.9261202812194824, 2.986955404281616, 2.8216140270233154, 1.852400302886963, 1.1302378177642822, 1.2568291425704956, 0.6411527395248413, 0.5581344366073608, 0.4785575568675995, 0.4769406020641327, 0.7358326315879822, 0.7111174464225769, 0.6971518993377686, 0.3908827006816864, 0.3907199203968048, 1.215394377708435, 0.3153114318847656, 0.31470856070518494, 0.3146860897541046, 0.3085930347442627, 0.38482537865638733, 0.31339240074157715, 0.23435790836811066, 0.23414219915866852, 0.23399567604064941, 0.23391428589820862, 0.23341584205627441, 0.3041873574256897, 0.22688160836696625, 0.22670458257198334, 0.22658200562000275, 0.3154473900794983, 0.4559425711631775, 0.7334238886833191, 2.470966100692749, 0.33462032675743103, 0.6531721949577332, 1.161769986152649, 0.7397707104682922, 0.5165445804595947, 2.364093780517578, 0.44989731907844543, 0.47112178802490234, 1.2466930150985718, 1.3705198764801025, 0.641107976436615, 0.8273770809173584, 0.8022860884666443, 0.84017413854599, 0.5965767502784729, 0.7313879132270813, 0.6913880109786987, 0.6194537281990051, 0.6021698117256165, 0.49446216225624084, 0.4825095534324646, 0.00011236192949581891, 0.00011234817065997049, 0.00011239693412790075, 0.0001123503316193819, 0.00011237344733672217, 0.00011237497528782114, 0.00011232987162657082, 0.00011236662976443768, 0.00011235559941269457, 0.00011230930977035314, 0.00011233764234930277, 0.00011237178841838613, 0.00011237922444706783, 0.00011235691636102274, 0.00011236657883273438, 0.00011235190322622657, 0.00011235563579248264, 0.00011236028512939811, 0.00011233770055696368, 0.00011234434350626543, 0.00011233122495468706, 0.00011232294491492212, 0.00011233142868150026, 0.00011250375973759219, 0.00011249311501160264, 0.00011247149086557329, 0.00011246564099565148, 0.00011246580834267661, 0.00011245853238506243, 0.00011243357585044578, 0.00011245303903706372, 0.00029642696608789265, 0.00017140255658887327, 0.0001793728006305173, 0.00016002274060156196, 0.00012919669097755104, 0.0001158175800810568, 0.0001257293624803424, 0.0001157856167992577, 0.00011574408563319594, 0.0001157340666395612, 0.00011572045332286507, 0.00011570753122214228, 0.00012528389925137162, 0.00013849411334376782, 0.00011567882756935433, 0.00013353141548577696, 0.00011565625754883513, 0.00011563166481209919, 0.00011562029976630583, 0.00011561236169654876, 0.00011560336861293763, 0.00011560044367797673, 0.00011559197446331382, 0.00011557894322322682, 0.00011557059042388573, 0.00011556271056178957, 0.00012902305752504617, 0.00012196876195957884, 0.00011553672084119171, 0.0001155345598817803, 0.00012641504872590303, 0.00011869638547068462, 0.00013421487528830767, 0.0001235690142493695, 0.00012514888658188283, 0.00011845133121823892, 0.00023929176677484065, 0.00021907591144554317, 0.0002457201771903783, 0.0001335575943812728, 0.00012469881039578468, 0.00012274693290237337, 0.00011836300109280273, 0.0002413513429928571, 0.00013236426457297057, 0.00012459747085813433, 0.00012364141002763063, 0.00011833486496470869, 0.00011827378330053762, 0.00015163881471380591, 0.00013761507580056787, 0.00012416923709679395, 0.00012412163778208196, 0.00022059070761315525, 0.00019407477520871907, 0.0001277243427466601, 0.00020124287402722985, 0.00019396704738028347, 0.00018999860913027078, 0.00018636243476066738, 0.0001877397735370323, 0.00018388939497526735, 0.00018948795332107693, 0.00018097434076480567, 0.00017707412189338356, 0.00017919052334036678, 0.00018347437435295433, 0.0001804795756470412, 0.00017823521920945495, 0.00017388112610206008, 0.00017103264690376818, 0.00017998911789618433, 0.00016807565407361835, 0.00016376150597352535, 0.0001680359710007906, 0.000166213940246962, 0.00016660244727972895, 0.0001667323667788878], \"Total\": [859.0, 1055.0, 1229.0, 1387.0, 609.0, 390.0, 1311.0, 164.0, 320.0, 409.0, 560.0, 292.0, 609.0, 409.0, 266.0, 122.0, 328.0, 456.0, 612.0, 185.0, 101.0, 456.0, 667.0, 614.0, 380.0, 106.0, 198.0, 212.0, 731.0, 422.0, 85.78877258300781, 72.18743133544922, 220.8351287841797, 248.01927185058594, 113.03093719482422, 682.6094970703125, 221.0021209716797, 197.93807983398438, 43.115047454833984, 44.01984786987305, 39.20249938964844, 49.03507995605469, 36.22442626953125, 46.394893646240234, 308.8720703125, 61.10057067871094, 127.65587615966797, 34.36931610107422, 34.34733963012695, 193.21676635742188, 422.7676696777344, 43.380218505859375, 33.294891357421875, 30.48110008239746, 36.907840728759766, 88.22742462158203, 34.98663330078125, 33.08662796020508, 28.514108657836914, 51.14057922363281, 402.31585693359375, 130.52590942382812, 85.62144470214844, 196.0250701904297, 79.5505142211914, 100.43563079833984, 578.42724609375, 220.0059356689453, 190.19921875, 226.08201599121094, 144.35821533203125, 840.5648193359375, 441.91900634765625, 127.27783966064453, 1055.74169921875, 1229.1336669921875, 292.1586608886719, 282.47314453125, 646.04248046875, 899.6622924804688, 384.99798583984375, 705.8949584960938, 353.66778564453125, 495.2377624511719, 431.8009948730469, 1311.2205810546875, 912.3809814453125, 390.7237854003906, 513.7049560546875, 917.2235107421875, 609.8779296875, 614.0919799804688, 1387.2703857421875, 467.10845947265625, 731.6046752929688, 736.8612670898438, 638.6544799804688, 458.846923828125, 509.7945556640625, 597.2691040039062, 667.0925903320312, 609.4708862304688, 612.1369018554688, 560.5264892578125, 53.03178024291992, 29.684106826782227, 26.513959884643555, 24.248178482055664, 22.697664260864258, 23.496715545654297, 78.92838287353516, 19.666170120239258, 30.095930099487305, 16.478981018066406, 16.428306579589844, 18.120765686035156, 102.99238586425781, 14.108528137207031, 20.14419174194336, 14.145995140075684, 13.334512710571289, 35.610809326171875, 17.43624496459961, 12.588849067687988, 13.368049621582031, 12.59337329864502, 15.678536415100098, 16.983007431030273, 11.810583114624023, 11.780402183532715, 11.817721366882324, 11.682357788085938, 11.808948516845703, 16.66613006591797, 51.4725341796875, 18.16889762878418, 24.709590911865234, 23.34503746032715, 136.9608917236328, 859.2841796875, 46.49715805053711, 191.70175170898438, 107.0107192993164, 74.19781494140625, 328.4743347167969, 72.57093811035156, 70.75537109375, 380.2916564941406, 409.8243408203125, 323.1940612792969, 75.58699798583984, 340.4057312011719, 197.87925720214844, 178.29713439941406, 89.09159088134766, 456.0722351074219, 266.1645812988281, 612.1369018554688, 409.5686340332031, 168.166748046875, 1311.2205810546875, 917.2235107421875, 1387.2703857421875, 192.9862518310547, 148.39584350585938, 183.0370635986328, 258.7453308105469, 667.0925903320312, 197.18919372558594, 422.7603454589844, 609.4708862304688, 736.8612670898438, 356.1620788574219, 597.2691040039062, 899.6622924804688, 912.3809814453125, 473.0506286621094, 1229.1336669921875, 731.6046752929688, 638.6544799804688, 560.5264892578125, 1055.74169921875, 61.000633239746094, 32.048553466796875, 26.32653045654297, 56.500640869140625, 42.568668365478516, 22.00403594970703, 19.100122451782227, 25.864038467407227, 106.9311294555664, 16.98052215576172, 15.525191307067871, 15.515209197998047, 15.537681579589844, 39.330509185791016, 15.810063362121582, 20.92201805114746, 13.351097106933594, 13.371878623962402, 12.628482818603516, 57.29813003540039, 16.43186378479004, 34.758270263671875, 185.7853546142578, 68.74281311035156, 16.48567771911621, 11.908812522888184, 13.609272956848145, 16.509056091308594, 30.852628707885742, 14.837289810180664, 54.674190521240234, 60.54734420776367, 36.11895751953125, 21.824872970581055, 266.1645812988281, 43.51215362548828, 32.440364837646484, 29.68840217590332, 108.21135711669922, 77.92833709716797, 98.69833374023438, 178.902587890625, 409.8243408203125, 409.5686340332031, 61.716468811035156, 1387.2703857421875, 456.0722351074219, 859.2841796875, 184.18441772460938, 667.0925903320312, 380.2916564941406, 609.4708862304688, 124.9310531616211, 912.3809814453125, 204.82064819335938, 459.8153991699219, 597.2691040039062, 731.6046752929688, 1311.2205810546875, 736.8612670898438, 705.8949584960938, 560.5264892578125, 917.2235107421875, 614.0919799804688, 370.74188232421875, 1055.74169921875, 48.90713882446289, 31.70003890991211, 16.015552520751953, 16.022314071655273, 13.94920825958252, 14.006394386291504, 16.259815216064453, 11.4362211227417, 10.895622253417969, 10.902108192443848, 10.95402717590332, 10.388354301452637, 10.413517951965332, 20.628644943237305, 15.969365119934082, 12.592090606689453, 13.385655403137207, 18.388813018798828, 12.27292537689209, 9.443891525268555, 8.860547065734863, 8.891039848327637, 8.914008140563965, 8.352082252502441, 16.844074249267578, 8.324854850769043, 8.987218856811523, 7.843040466308594, 7.842583179473877, 31.24774169921875, 47.13602828979492, 17.741806030273438, 19.07843017578125, 15.041703224182129, 27.195743560791016, 120.4556655883789, 26.758729934692383, 292.710205078125, 81.97122955322266, 212.67869567871094, 609.8779296875, 205.56834411621094, 320.87188720703125, 112.52212524414062, 54.82530212402344, 859.2841796875, 328.4743347167969, 1229.1336669921875, 180.69667053222656, 305.7286376953125, 473.0506286621094, 151.2981414794922, 1387.2703857421875, 667.0925903320312, 226.8903045654297, 560.5264892578125, 350.16534423828125, 731.6046752929688, 614.0919799804688, 912.3809814453125, 1311.2205810546875, 638.6544799804688, 292.1586608886719, 372.3279724121094, 736.8612670898438, 899.6622924804688, 22.067880630493164, 13.728811264038086, 10.197866439819336, 15.104866981506348, 9.850690841674805, 10.063145637512207, 8.720433235168457, 8.366572380065918, 7.693467617034912, 7.754987716674805, 12.703988075256348, 7.820730209350586, 9.794357299804688, 7.37526798248291, 10.390283584594727, 11.88532543182373, 6.922850608825684, 6.978655815124512, 7.49911642074585, 6.9943695068359375, 6.555142402648926, 6.617263317108154, 6.618508338928223, 10.355271339416504, 6.1924214363098145, 19.7852783203125, 5.822492599487305, 6.361276149749756, 6.37141227722168, 5.84523344039917, 40.264404296875, 8.974404335021973, 28.458040237426758, 30.37531089782715, 17.614418029785156, 73.14672088623047, 64.02310943603516, 12.175419807434082, 13.891226768493652, 47.69578552246094, 82.29205322265625, 49.55927276611328, 130.17303466796875, 23.55851173400879, 1055.74169921875, 390.7237854003906, 106.38032531738281, 320.87188720703125, 560.5264892578125, 1229.1336669921875, 54.25004577636719, 1387.2703857421875, 1311.2205810546875, 106.47669982910156, 152.53907775878906, 609.4708862304688, 169.16848754882812, 614.0919799804688, 239.9569091796875, 72.1599349975586, 840.5648193359375, 899.6622924804688, 9.119145393371582, 8.49134349822998, 7.0777764320373535, 7.291722297668457, 5.443159103393555, 10.04593276977539, 7.197528839111328, 7.612000942230225, 5.229064464569092, 6.083926200866699, 4.656379222869873, 4.656473159790039, 4.6587605476379395, 4.659731864929199, 8.890125274658203, 4.814903259277344, 4.834227085113525, 4.462287902832031, 4.600366592407227, 6.708287715911865, 11.19960880279541, 5.184047698974609, 6.312117576599121, 4.396632671356201, 13.946720123291016, 4.068082332611084, 4.069979667663574, 4.070155620574951, 4.071211338043213, 4.181156635284424, 5.229385852813721, 6.054242134094238, 44.822330474853516, 44.77043914794922, 164.51470947265625, 106.47669982910156, 101.31055450439453, 33.88455581665039, 22.5752010345459, 16.572734832763672, 55.8277473449707, 122.49047088623047, 39.75248336791992, 43.88495635986328, 50.84387969970703, 36.55173873901367, 409.8243408203125, 69.00196838378906, 204.82064819335938, 1387.2703857421875, 456.19793701171875, 609.4708862304688, 859.2841796875, 422.7603454589844, 1311.2205810546875, 253.89190673828125, 212.54148864746094, 5.8076276779174805, 5.160740375518799, 7.260995388031006, 4.064433574676514, 3.9729185104370117, 3.8416850566864014, 3.8599205017089844, 6.345407485961914, 6.501534938812256, 6.3826398849487305, 3.7600197792053223, 3.764028310775757, 12.52531623840332, 3.6318583488464355, 3.637516736984253, 3.6387710571289062, 3.664142608642578, 4.8332438468933105, 4.423742771148682, 3.5183985233306885, 3.520768404006958, 3.522181510925293, 3.5230085849761963, 3.5282320976257324, 4.716491222381592, 3.5633163452148438, 3.5648553371429443, 3.5652995109558105, 4.986922740936279, 7.330221652984619, 12.021242141723633, 47.591556549072266, 5.787064552307129, 13.386802673339844, 30.095930099487305, 17.111000061035156, 11.44390869140625, 122.49047088623047, 10.361186027526855, 11.377856254577637, 95.14399719238281, 178.29713439941406, 36.55173873901367, 89.48489379882812, 114.91853332519531, 144.35821533203125, 38.905521392822266, 120.4556655883789, 95.1610107421875, 82.34549713134766, 136.9608917236328, 35.7706184387207, 38.735435485839844, 3.405524730682373, 3.4052023887634277, 3.4072625637054443, 3.4061949253082275, 3.4069206714630127, 3.407076358795166, 3.4060168266296387, 3.407210111618042, 3.4071176052093506, 3.4059860706329346, 3.4069178104400635, 3.408062696456909, 3.4082915782928467, 3.4076321125030518, 3.408209800720215, 3.407829761505127, 3.407956838607788, 3.408216714859009, 3.4076461791992188, 3.408522129058838, 3.408562183380127, 3.408662796020508, 3.4094302654266357, 3.445594310760498, 3.4453370571136475, 3.44565749168396, 3.445516347885132, 3.4457836151123047, 3.4456870555877686, 3.444950819015503, 3.445617914199829, 75.58699798583984, 20.14419174194336, 28.693702697753906, 20.646087646484375, 7.0404558181762695, 4.013859272003174, 6.2810564041137695, 4.013855934143066, 4.0138840675354, 4.014199733734131, 4.014130592346191, 4.014190196990967, 6.28665018081665, 11.396928787231445, 4.014466285705566, 9.34803295135498, 4.014321327209473, 4.01466703414917, 4.014679908752441, 4.014760971069336, 4.015092372894287, 4.0146636962890625, 4.014495849609375, 4.015132904052734, 4.0152130126953125, 4.014967441558838, 7.820562839508057, 5.530300617218018, 4.015268325805664, 4.015563011169434, 7.056253433227539, 4.773207187652588, 10.89573860168457, 6.298048973083496, 7.066505432128906, 4.773767948150635, 859.2841796875, 456.19793701171875, 1229.1336669921875, 11.664764404296875, 7.076388359069824, 6.303515911102295, 4.774815082550049, 1311.2205810546875, 11.576397895812988, 7.142138481140137, 6.747705936431885, 4.774265289306641, 4.775212287902832, 40.272274017333984, 16.983007431030273, 7.258563995361328, 7.260155200958252, 1387.2703857421875, 612.1369018554688, 9.546785354614258, 912.3809814453125, 667.0925903320312, 646.04248046875, 560.5264892578125, 638.6544799804688, 614.0919799804688, 899.6622924804688, 597.2691040039062, 473.0506286621094, 609.8779296875, 917.2235107421875, 731.6046752929688, 705.8949584960938, 513.7049560546875, 409.8243408203125, 1055.74169921875, 459.8153991699219, 342.5302429199219, 736.8612670898438, 609.4708862304688, 682.6094970703125, 840.5648193359375], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.075799942016602, -7.251999855041504, -6.141600131988525, -6.027100086212158, -6.816199779510498, -5.019499778747559, -6.150199890136719, -6.266499996185303, -7.791200160980225, -7.772799968719482, -7.892000198364258, -7.673900127410889, -7.977499961853027, -7.731200218200684, -5.83620023727417, -7.456999778747559, -6.720600128173828, -8.032899856567383, -8.034500122070312, -6.3094000816345215, -5.526400089263916, -7.805099964141846, -8.070500373840332, -8.163100242614746, -7.972099781036377, -7.100599765777588, -8.025699615478516, -8.084699630737305, -8.234600067138672, -7.650599956512451, -5.593400001525879, -6.713900089263916, -7.135200023651123, -6.315999984741211, -7.210299968719482, -6.980800151824951, -5.2540998458862305, -6.212200164794922, -6.357399940490723, -6.196000099182129, -6.632900238037109, -4.926499843597412, -5.55049991607666, -6.758500099182129, -4.749100208282471, -4.604800224304199, -5.970699787139893, -6.005000114440918, -5.232699871063232, -4.922399997711182, -5.719399929046631, -5.163700103759766, -5.81220006942749, -5.51609992980957, -5.639800071716309, -4.658400058746338, -4.983099937438965, -5.731800079345703, -5.507500171661377, -5.032700061798096, -5.384799957275391, -5.379700183868408, -4.719799995422363, -5.602099895477295, -5.251999855041504, -5.251399993896484, -5.370299816131592, -5.623600006103516, -5.5680999755859375, -5.494699954986572, -5.474100112915039, -5.539400100708008, -5.551199913024902, -5.611199855804443, -6.348800182342529, -6.969900131225586, -7.097400188446045, -7.194499969482422, -7.267600059509277, -7.234899997711182, -6.039000034332275, -7.453499794006348, -7.030900001525879, -7.63700008392334, -7.640600204467773, -7.55210018157959, -5.815199851989746, -7.822800159454346, -7.4670000076293945, -7.820799827575684, -7.8927001953125, -6.916600227355957, -7.636600017547607, -7.965000152587891, -7.908299922943115, -7.968299865722656, -7.757500171661377, -7.680600166320801, -8.045000076293945, -8.048199653625488, -8.046899795532227, -8.070599555969238, -8.059900283813477, -7.71560001373291, -6.591100215911865, -7.639500141143799, -7.348400115966797, -7.405099868774414, -5.783999919891357, -4.1168999671936035, -6.787300109863281, -5.537600040435791, -6.076300144195557, -6.407599925994873, -5.138500213623047, -6.444799900054932, -6.468699932098389, -5.156000137329102, -5.11959981918335, -5.333700180053711, -6.478099822998047, -5.3256001472473145, -5.753399848937988, -5.8403000831604, -6.370200157165527, -5.176300048828125, -5.579599857330322, -4.996300220489502, -5.328400135040283, -5.940199851989746, -4.852799892425537, -5.059999942779541, -4.826900005340576, -5.966800212860107, -6.117300033569336, -6.021999835968018, -5.893799781799316, -5.489999771118164, -6.031499862670898, -5.727099895477295, -5.581399917602539, -5.5457000732421875, -5.837200164794922, -5.677499771118164, -5.58050012588501, -5.641499996185303, -5.792500019073486, -5.628399848937988, -5.719699859619141, -5.7480998039245605, -5.809299945831299, -5.819699764251709, -5.914999961853027, -6.601200103759766, -6.816100120544434, -6.061100006103516, -6.360300064086914, -7.022299766540527, -7.179900169372559, -6.879300117492676, -5.4629998207092285, -7.322999954223633, -7.424699783325195, -7.4253997802734375, -7.42609977722168, -6.504000186920166, -7.420300006866455, -7.150599956512451, -7.608500003814697, -7.609799861907959, -7.678199768066406, -6.167900085449219, -7.422399997711182, -6.674699783325195, -5.0005998611450195, -5.997300148010254, -7.426799774169922, -7.752500057220459, -7.620299816131592, -7.43149995803833, -6.806600093841553, -7.546199798583984, -6.252699851989746, -6.228600025177002, -6.720399856567383, -7.184999942779541, -5.049799919128418, -6.601099967956543, -6.85699987411499, -6.936299800872803, -5.985899925231934, -6.242700099945068, -6.183700084686279, -5.809500217437744, -5.289100170135498, -5.330699920654297, -6.524700164794922, -4.680600166320801, -5.394100189208984, -5.206399917602539, -5.997399806976318, -5.436699867248535, -5.753900051116943, -5.571000099182129, -6.232999801635742, -5.44350004196167, -6.048999786376953, -5.76170015335083, -5.68149995803833, -5.63070011138916, -5.486499786376953, -5.68179988861084, -5.848299980163574, -5.9309000968933105, -5.8780999183654785, -5.950699806213379, -6.064700126647949, -6.010900020599365, -5.452300071716309, -5.912499904632568, -6.6529998779296875, -6.65339994430542, -6.819799900054932, -6.825399875640869, -6.690299987792969, -7.081299781799316, -7.139599800109863, -7.139999866485596, -7.149099826812744, -7.204400062561035, -7.207200050354004, -6.523900032043457, -6.781199932098389, -7.02869987487793, -6.980000019073486, -6.67140007019043, -7.092800140380859, -7.3649001121521, -7.429200172424316, -7.435400009155273, -7.440299987792969, -7.517199993133545, -6.818900108337402, -7.527699947357178, -7.462100028991699, -7.613100051879883, -7.613399982452393, -6.231400012969971, -5.841100215911865, -6.866499900817871, -6.841000080108643, -7.047699928283691, -6.585999965667725, -5.463399887084961, -6.650700092315674, -5.106900215148926, -5.962399959564209, -5.474999904632568, -4.950500011444092, -5.551400184631348, -5.3531999588012695, -5.915900230407715, -6.392199993133545, -5.155900001525879, -5.617000102996826, -5.095600128173828, -5.925000190734863, -5.752500057220459, -5.665999889373779, -6.082900047302246, -5.351799964904785, -5.609099864959717, -5.955900192260742, -5.721700191497803, -5.85890007019043, -5.66510009765625, -5.758399963378906, -5.656300067901611, -5.567399978637695, -5.772299766540527, -5.986499786376953, -5.957099914550781, -5.91379976272583, -5.895400047302246, -5.706600189208984, -6.26669979095459, -6.62529993057251, -6.237599849700928, -6.678100109100342, -6.6975998878479, -6.848100185394287, -6.914400100708008, -7.06879997253418, -7.07390022277832, -6.593100070953369, -7.081699848175049, -6.859799861907959, -7.15310001373291, -6.820400238037109, -6.688600063323975, -7.229300022125244, -7.2434000968933105, -7.172299861907959, -7.246600151062012, -7.32480001449585, -7.342100143432617, -7.342400074005127, -6.913899898529053, -7.432199954986572, -6.282400131225586, -7.549799919128418, -7.464900016784668, -7.465799808502197, -7.554599761962891, -5.704699993133545, -7.148900032043457, -6.087200164794922, -6.106599807739258, -6.60230016708374, -5.547699928283691, -5.697000026702881, -6.940700054168701, -6.865099906921387, -6.14300012588501, -5.844699859619141, -6.166200160980225, -5.6996002197265625, -6.625800132751465, -4.8734002113342285, -5.341800212860107, -5.937900066375732, -5.4857001304626465, -5.456399917602539, -5.196800231933594, -6.332300186157227, -5.267499923706055, -5.460999965667725, -6.168799877166748, -6.101900100708008, -5.869100093841553, -6.258999824523926, -6.118800163269043, -6.299799919128418, -6.4679999351501465, -6.33620023727417, -6.377200126647949, -5.942399978637695, -6.051799774169922, -6.37060022354126, -6.468599796295166, -6.8155999183654785, -6.245699882507324, -6.696000099182129, -6.644400119781494, -7.024400234222412, -6.904600143432617, -7.226399898529053, -7.226500034332275, -7.226600170135498, -7.226900100708008, -6.605500221252441, -7.253200054168701, -7.256800174713135, -7.36269998550415, -7.388800144195557, -7.014400005340576, -6.529399871826172, -7.333600044250488, -7.15500020980835, -7.549900054931641, -6.472700119018555, -7.706999778747559, -7.707399845123291, -7.707499980926514, -7.708000183105469, -7.7368998527526855, -7.518099784851074, -7.380099773406982, -5.5117998123168945, -5.796599864959717, -4.822500228881836, -5.206200122833252, -5.276500225067139, -6.154699802398682, -6.598599910736084, -6.80019998550415, -6.298099994659424, -6.126100063323975, -6.536499977111816, -6.5381999015808105, -6.526400089263916, -6.6315999031066895, -6.0329999923706055, -6.570000171661377, -6.32289981842041, -6.046299934387207, -6.296999931335449, -6.2546000480651855, -6.252600193023682, -6.350500106811523, -6.2683000564575195, -6.5416998863220215, -6.598599910736084, -6.0040998458862305, -6.4980998039245605, -6.392000198364258, -7.065000057220459, -7.203700065612793, -7.357500076293945, -7.360899925231934, -6.927299976348877, -6.96150016784668, -6.981299877166748, -7.559899806976318, -7.560299873352051, -6.42549991607666, -7.774700164794922, -7.776700019836426, -7.776700019836426, -7.796299934387207, -7.575500011444092, -7.780900001525879, -8.071499824523926, -8.072400093078613, -8.072999954223633, -8.073399543762207, -8.075499534606934, -7.810699939727783, -8.103899955749512, -8.104700088500977, -8.105199813842773, -7.7743000984191895, -7.405900001525879, -6.930600166320801, -5.71589994430542, -7.7153000831604, -7.046500205993652, -6.470600128173828, -6.921999931335449, -7.281099796295166, -5.760200023651123, -7.419300079345703, -7.373199939727783, -6.400100231170654, -6.3053998947143555, -7.065100193023682, -6.809999942779541, -6.840799808502197, -6.7947001457214355, -7.1371002197265625, -6.9334001541137695, -6.98960018157959, -7.0995001792907715, -7.127799987792969, -7.32480001449585, -7.349299907684326, -9.094300270080566, -9.094400405883789, -9.093999862670898, -9.094400405883789, -9.094200134277344, -9.094200134277344, -9.094599723815918, -9.094200134277344, -9.094300270080566, -9.09469985961914, -9.094499588012695, -9.094200134277344, -9.094099998474121, -9.094300270080566, -9.094200134277344, -9.094400405883789, -9.094300270080566, -9.094300270080566, -9.094499588012695, -9.094400405883789, -9.094499588012695, -9.094599723815918, -9.094499588012695, -9.093000411987305, -9.093099594116211, -9.093299865722656, -9.093400001525879, -9.093400001525879, -9.093400001525879, -9.093600273132324, -9.093500137329102, -8.124199867248535, -8.67199993133545, -8.626500129699707, -8.740699768066406, -8.954700469970703, -9.064000129699707, -8.981900215148926, -9.064299583435059, -9.064599990844727, -9.06470012664795, -9.064800262451172, -9.064900398254395, -8.985400199890137, -8.885199546813965, -9.065199851989746, -8.921699523925781, -9.065400123596191, -9.065600395202637, -9.065699577331543, -9.065799713134766, -9.065799713134766, -9.065899848937988, -9.065899848937988, -9.065999984741211, -9.066100120544434, -9.066200256347656, -8.956000328063965, -9.012200355529785, -9.066399574279785, -9.066399574279785, -8.976400375366211, -9.039400100708008, -8.916600227355957, -8.999199867248535, -8.986499786376953, -9.041500091552734, -8.338299751281738, -8.426600456237793, -8.311800003051758, -8.921500205993652, -8.990099906921387, -9.005900382995605, -9.042200088500977, -8.329700469970703, -8.930399894714355, -8.990900039672852, -8.998600006103516, -9.042499542236328, -9.043000221252441, -8.794500350952148, -8.891500473022461, -8.994400024414062, -8.99470043182373, -8.419699668884277, -8.547800064086914, -8.966099739074707, -8.511500358581543, -8.548299789428711, -8.569000244140625, -8.588299751281738, -8.580900192260742, -8.601699829101562, -8.571700096130371, -8.617600440979004, -8.639399528503418, -8.627599716186523, -8.603899955749512, -8.620400428771973, -8.63290023803711, -8.657600402832031, -8.674099922180176, -8.623100280761719, -8.69159984588623, -8.717599868774414, -8.691800117492676, -8.702699661254883, -8.700400352478027, -8.699600219726562]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el24981405141717755681879257859\", ldavis_el24981405141717755681879257859_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el24981405141717755681879257859\", ldavis_el24981405141717755681879257859_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el24981405141717755681879257859\", ldavis_el24981405141717755681879257859_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "7      58.895950        1       1 -0.168808 -0.034076\n",
       "1      17.232506        1       2 -0.076027  0.055721\n",
       "5      12.918425        1       3 -0.053432  0.054010\n",
       "6       6.068927        1       4 -0.022521 -0.047228\n",
       "3       3.192707        1       5  0.023060 -0.043905\n",
       "2       1.241229        1       6  0.070890  0.008933\n",
       "0       0.449649        1       7  0.107736  0.008278\n",
       "4       0.000600        1       8  0.119102 -0.001734, topic_info=     Category         Freq         Term        Total  loglift  logprob\n",
       "2368  Default   859.000000      network   859.000000  30.0000  30.0000\n",
       "2732  Default  1055.000000        datum  1055.000000  29.0000  29.0000\n",
       "1366  Default  1229.000000          set  1229.000000  28.0000  28.0000\n",
       "7552  Default  1387.000000        model  1387.000000  27.0000  27.0000\n",
       "1441  Default   609.000000        error   609.000000  26.0000  26.0000\n",
       "7713  Default   390.000000       matrix   390.000000  25.0000  25.0000\n",
       "8298  Default  1311.000000          use  1311.000000  24.0000  24.0000\n",
       "249   Default   164.000000       object   164.000000  23.0000  23.0000\n",
       "5582  Default   320.000000      cluster   320.000000  22.0000  22.0000\n",
       "1832  Default   409.000000       system   409.000000  21.0000  21.0000\n",
       "1274  Default   560.000000       number   560.000000  20.0000  20.0000\n",
       "7303  Default   292.000000         term   292.000000  19.0000  19.0000\n",
       "7255  Default   609.000000       figure   609.000000  18.0000  18.0000\n",
       "1482  Default   409.000000        input   409.000000  17.0000  17.0000\n",
       "4225  Default   266.000000       neuron   266.000000  16.0000  16.0000\n",
       "569   Default   122.000000      current   122.000000  15.0000  15.0000\n",
       "4364  Default   328.000000       weight   328.000000  14.0000  14.0000\n",
       "4166  Default   456.000000        state   456.000000  13.0000  13.0000\n",
       "716   Default   612.000000     training   612.000000  12.0000  12.0000\n",
       "615   Default   185.000000       visual   185.000000  11.0000  11.0000\n",
       "6438  Default   101.000000  formulation   101.000000  10.0000  10.0000\n",
       "1004  Default   456.000000        image   456.000000   9.0000   9.0000\n",
       "522   Default   667.000000         time   667.000000   8.0000   8.0000\n",
       "4515  Default   614.000000         give   614.000000   7.0000   7.0000\n",
       "6463  Default   380.000000       neural   380.000000   6.0000   6.0000\n",
       "8523  Default   106.000000         view   106.000000   5.0000   5.0000\n",
       "310   Default   198.000000       convex   198.000000   4.0000   4.0000\n",
       "7328  Default   212.000000       theory   212.000000   3.0000   3.0000\n",
       "5232  Default   731.000000         show   731.000000   2.0000   2.0000\n",
       "4434  Default   422.000000       vector   422.000000   1.0000   1.0000\n",
       "...       ...          ...          ...          ...      ...      ...\n",
       "3335   Topic8     0.000118     darkness     4.775212   1.4186  -9.0430\n",
       "1825   Topic8     0.000152        scene    40.272274  -0.4652  -8.7945\n",
       "3765   Topic8     0.000138     subtract    16.983007   0.3013  -8.8915\n",
       "4700   Topic8     0.000124         blur     7.258564   1.0485  -8.9944\n",
       "4122   Topic8     0.000124       indoor     7.260155   1.0479  -8.9947\n",
       "7552   Topic8     0.000221        model  1387.270386  -3.6298  -8.4197\n",
       "716    Topic8     0.000194     training   612.136902  -2.9397  -8.5478\n",
       "809    Topic8     0.000128       bright     9.546785   0.8027  -8.9661\n",
       "2132   Topic8     0.000201     function   912.380981  -3.3025  -8.5115\n",
       "522    Topic8     0.000194         time   667.092590  -3.0262  -8.5483\n",
       "5836   Topic8     0.000190        point   646.042480  -3.0148  -8.5690\n",
       "1274   Topic8     0.000186       number   560.526489  -2.8922  -8.5883\n",
       "3479   Topic8     0.000188         base   638.654480  -3.0153  -8.5809\n",
       "4515   Topic8     0.000184         give   614.091980  -2.9968  -8.6017\n",
       "4180   Topic8     0.000189      problem   899.662292  -3.3487  -8.5717\n",
       "3329   Topic8     0.000181        value   597.269104  -2.9850  -8.6176\n",
       "5210   Topic8     0.000177  performance   473.050629  -2.7736  -8.6394\n",
       "1441   Topic8     0.000179        error   609.877930  -3.0158  -8.6276\n",
       "1175   Topic8     0.000183        learn   917.223511  -3.4003  -8.6039\n",
       "5232   Topic8     0.000180         show   731.604675  -3.1906  -8.6204\n",
       "101    Topic8     0.000178      feature   705.894958  -3.1674  -8.6329\n",
       "5899   Topic8     0.000174         task   513.704956  -2.8743  -8.6576\n",
       "1832   Topic8     0.000171       system   409.824341  -2.6649  -8.6741\n",
       "2732   Topic8     0.000180        datum  1055.741699  -3.5601  -8.6231\n",
       "5338   Topic8     0.000168    different   459.815399  -2.7974  -8.6916\n",
       "1372   Topic8     0.000164          see   342.530243  -2.5289  -8.7176\n",
       "305    Topic8     0.000168       result   736.861267  -3.2692  -8.6918\n",
       "7255   Topic8     0.000166       figure   609.470886  -3.0903  -8.7027\n",
       "5063   Topic8     0.000167       sample   682.609497  -3.2013  -8.7004\n",
       "1134   Topic8     0.000167       method   840.564819  -3.4087  -8.6996\n",
       "\n",
       "[595 rows x 6 columns], token_table=      Topic      Freq              Term\n",
       "term                                   \n",
       "6615      1  0.209432         abundance\n",
       "6615      2  0.418864         abundance\n",
       "6615      3  0.209432         abundance\n",
       "328       1  0.249058          accident\n",
       "328       2  0.249058          accident\n",
       "328       3  0.249058          accident\n",
       "1150      1  0.343675            action\n",
       "1150      2  0.424540            action\n",
       "1150      3  0.208901            action\n",
       "1150      4  0.013477            action\n",
       "1409      1  0.402491        adaptation\n",
       "1409      2  0.251557        adaptation\n",
       "1409      3  0.251557        adaptation\n",
       "1409      6  0.075467        adaptation\n",
       "5062      1  0.050679             agent\n",
       "5062      2  0.874210             agent\n",
       "5062      3  0.063349             agent\n",
       "5756      1  0.157201           aileron\n",
       "5756      2  0.157201           aileron\n",
       "5756      3  0.157201           aileron\n",
       "5756      5  0.471603           aileron\n",
       "1608      1  0.864412         algorithm\n",
       "1608      2  0.079200         algorithm\n",
       "1608      3  0.013577         algorithm\n",
       "1608      4  0.029417         algorithm\n",
       "1608      5  0.013577         algorithm\n",
       "7736      1  0.349531             align\n",
       "7736      2  0.349531             align\n",
       "7736      3  0.174765             align\n",
       "7736      7  0.087383             align\n",
       "...     ...       ...               ...\n",
       "6481      6  0.082075           voltage\n",
       "6481      7  0.027358           voltage\n",
       "913       1  0.260302           voronoi\n",
       "913       2  0.260302           voronoi\n",
       "913       3  0.260302           voronoi\n",
       "431       1  0.156951           warping\n",
       "431       2  0.156951           warping\n",
       "431       3  0.156951           warping\n",
       "431       5  0.470853           warping\n",
       "4145      1  0.072840  warping_function\n",
       "4145      2  0.072840  warping_function\n",
       "4145      3  0.072840  warping_function\n",
       "4145      5  0.728395  warping_function\n",
       "6269      1  0.280637         wavefront\n",
       "6269      2  0.280637         wavefront\n",
       "6269      3  0.280637         wavefront\n",
       "4564      1  0.086383          weakness\n",
       "4564      2  0.777444          weakness\n",
       "4564      3  0.086383          weakness\n",
       "4364      1  0.283127            weight\n",
       "4364      2  0.514500            weight\n",
       "4364      3  0.085243            weight\n",
       "4364      4  0.112642            weight\n",
       "4364      5  0.003044            weight\n",
       "3911      1  0.259073               win\n",
       "3911      2  0.259073               win\n",
       "3911      3  0.259073               win\n",
       "2282      1  0.058891              worm\n",
       "2282      2  0.058891              worm\n",
       "2282      3  0.824474              worm\n",
       "\n",
       "[1923 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[8, 2, 6, 7, 4, 3, 1, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "\n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
